{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "#| eval: falseq\n",
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Language Modelling with RNNs\"\n",
    "author: Deepam Minda\n",
    "date: \"July 20, 2024\"\n",
    "categories: [rnns, nlp, seq-to-seq, langauge-modelling]\n",
    "format:\n",
    "  html:\n",
    "    toc: true\n",
    "    toc-depth: 3\n",
    "    html-math-method: katex\n",
    "    code-fold: true\n",
    "    code-summary: \"show code\"\n",
    "    highlight-style: github\n",
    "  ipynb: default\n",
    "execute:\n",
    "  warning: false\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The only reason you would be hearing RNNs right now is probably when [xLSTMs](https://arxiv.org/pdf/2405.04517) were released in May, 2024. Apart from this they have pretty much taken a back seat to watch transformers revolutionalize NLP and the entire field of AI in general. \n",
    "\n",
    "But one would do well to remember how we got here, and RNNs played a massive role in bringing us here. So in this blog post I'm going to build a small RNN model and we'll try to train it to generate text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data and process it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import numpy as np \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us load a text dataset. I downloaded a few mystery books and concatenated their raw text to make the dataset. Follow [this](https://github.com/mindadeepam/mindadeepam.github.io/blob/posts/posts/rnns/corpus.txt) link to get the text file. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of data: 3062155 characters\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: false\n",
    "dataset_path = \"/Users/deepamminda/Downloads/corpus.txt\"\n",
    "\n",
    "with open(dataset_path, 'r') as f:\n",
    "    data = f.read()\n",
    "print(f\"the size of data: {len(data)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look at some of the text we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data chunk:\n",
      "'n one of his own high-power lenses, would not\n",
      "be more disturbing than a strong emotion in a nature such as his. And\n",
      "yet there was but one woman to him, and that woman was the late Irene\n",
      "Adler, of dubious and questionable memory.\n",
      "\n",
      "I had seen little of Holmes lately. My marriage had drifted us away\n",
      "from each other. My own complete happiness, and the home-centred\n",
      "interests which rise up around the man who first finds himself master\n",
      "of his own establishment, were sufficient to absorb all my attention,\n",
      "while Holmes, who loathed every form of society with his whole Bohemian\n",
      "soul, remained in our lodgings in Baker Street, buried among his old\n",
      "books, and alternating from week to week between cocaine and ambition,\n",
      "the drowsiness of the drug, and the fierce energy of his own keen\n",
      "nature. He was still, as ever, deeply attracted by the study of crime,\n",
      "and occupied his immense faculties and extraordinary powers of\n",
      "observation in following out those clues, and clearing up those\n",
      "mysteries which had b'\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sample data chunk:\\n'{data[1500:2500]}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets split the data into train and test (80-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size: 2449724, test_size: 612431  (in number of tokens)\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(data) * 0.8)\n",
    "train_data, test_data = data[:train_size], data[train_size:]\n",
    "\n",
    "print(f\"train_size: {len(train_data)}, test_size: {len(test_data)}  (in number of tokens)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us encode the text to numerical data that our model can understand. Encoding the data generally means tokenization and then encoding. To keep it super simple, we'll just use individual characters as tokens.\n",
    "\n",
    "Nowadays however, subword [tokenization algorithms]((https://huggingface.co/docs/transformers/main/en/tokenizer_summary)) like Byte-Pair Encoding are the norm. But let us not get caught up in those for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "# Define the vocabulary and special tokens\n",
    "vocab = list(set(train_data+\"12345678910qwertyuioplkjhgfdsamnbvcxz~!@#$%^&*()_+`-=[];'./,{}\\\":?><\\|\"))\n",
    "PAD_TOKEN = '<pad>'\n",
    "special_tokens = [PAD_TOKEN]\n",
    "MAX_SEQ_LEN = 32\n",
    "\n",
    "vocab = [*special_tokens, *vocab]\n",
    "\n",
    "# Create mappings for encoding and decoding\n",
    "decode_mapping = dict(enumerate(vocab))\n",
    "encode_mapping = {v:k for k,v in decode_mapping.items()}\n",
    "\n",
    "# Define encoding and decoding functions\n",
    "encode = lambda text: [encode_mapping[char] for char in text]\n",
    "decode = lambda text: [decode_mapping[char] for char in text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can do a simple sanity check by encoding a text and decoding it. we should get the original string back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original text: hey there\n",
      "tokenized text: ['h', 'e', 'y', ' ', 't', 'h', 'e', 'r', 'e']\n",
      "encoded text: [104, 81, 106, 37, 89, 104, 81, 8, 81]\n",
      "decoded back:['h', 'e', 'y', ' ', 't', 'h', 'e', 'r', 'e']\n"
     ]
    }
   ],
   "source": [
    "text = \"hey there\"\n",
    "encoded_text = encode(text)\n",
    "\n",
    "print(f\"original text: {text}\")\n",
    "print(f\"tokenized text: {list(text)}\")\n",
    "print(f'encoded text: {encoded_text}')\n",
    "print(f\"decoded back:{decode(encoded_text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need functions that will do this for batches of texts rather than single text. \n",
    "When dealing with batches, there are a few extra considerations: \n",
    "- You would typically want your batches to contain texts which are of same length, so that matrix/tensor operations can be performed. Hence we need to truncate longer sentences and pad shorter sentences to a fixed length.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "#| code-fold: false\n",
    "\n",
    "def tokenize_arr(texts, max_seq_len=256):\n",
    "    \"\"\"\n",
    "    Tokenizes a list of texts and returns the tokenized array.\n",
    "\n",
    "    Args:\n",
    "        texts (list): A list of texts to be tokenized.\n",
    "        max_seq_len (int, optional): The maximum sequence length. Defaults to 256.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The tokenized array.\n",
    "\n",
    "    \"\"\"\n",
    "    # texts = pad_texts(texts, max_seq_len=MAX_SEQ_LEN)\n",
    "    texts = np.array(texts).reshape(-1,1)\n",
    "\n",
    "    texts = [list(doc) for text in texts for doc in text]\n",
    "    for i, text in enumerate(texts):\n",
    "        if len(text)>max_seq_len:\n",
    "            texts[i] = text[:max_seq_len]\n",
    "        elif len(text)<max_seq_len:\n",
    "            num_pad_tokens = max_seq_len-len(text)\n",
    "            texts[i] = [*([PAD_TOKEN]*num_pad_tokens) + text]\n",
    "    \n",
    "    return np.array(texts)\n",
    "\n",
    "def encode_arr(texts, encode_mapping=encode_mapping, max_seq_len=MAX_SEQ_LEN):\n",
    "    \"\"\"\n",
    "    Encodes an array of texts using a given encoding mapping.\n",
    "\n",
    "    Args:\n",
    "        texts (numpy.ndarray): The array of texts to be encoded.\n",
    "        encode_mapping (dict): A dictionary mapping characters to their corresponding encodings.\n",
    "        max_seq_len (int): The maximum sequence length.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The encoded texts.\n",
    "\n",
    "    \"\"\"\n",
    "    texts = tokenize_arr(texts, max_seq_len)\n",
    "    # print(texts)\n",
    "    texts = np.apply_along_axis(lambda text: [encode_mapping.get(x) for x in text], arr=texts, axis=1)\n",
    "    return texts.squeeze()\n",
    "\n",
    "def decode_arr(texts):\n",
    "    \"\"\"\n",
    "    Decodes a list of encoded texts using a decoding mapping.\n",
    "    \n",
    "    Parameters:\n",
    "    texts (numpy.ndarray): A numpy array of encoded texts.\n",
    "    \n",
    "    Returns:\n",
    "    list: A list of decoded texts.\n",
    "    \"\"\"\n",
    "    decoded_texts = np.apply_along_axis(lambda text: ([decode_mapping[x] for x in text]), arr=texts, axis=1)\n",
    "    decoded_texts = decoded_texts.tolist()\n",
    "    decoded_texts = [\"\".join(text) for text in decoded_texts]\n",
    "    return decoded_texts\n",
    "\n",
    "\n",
    "texts = [['hey there', \"talk much\", \"kendirck is cool af\"]]\n",
    "encoded_texts = encode_arr(texts)\n",
    "decoded_texts = decode_arr(encoded_texts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity let us also define a function that will fetch us a random batch of data from our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "def get_data(data, batch_size=16, seq_len=256):\n",
    "    \"\"\"\n",
    "    Retrieves input and target data for training a recurrent neural network (RNN).\n",
    "\n",
    "    Args:\n",
    "        data (list): The input data.\n",
    "        batch_size (int, optional): The number of sequences in each batch. Defaults to 16.\n",
    "        seq_len (int, optional): The length of each sequence. Defaults to 256.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the input and target data tensors.\n",
    "            - inputs (torch.Tensor): The input data tensor.\n",
    "            - targets (torch.Tensor): The target data tensor.\n",
    "    \"\"\"\n",
    "    buffer = 1000\n",
    "    l = len(data)\n",
    "    start = np.random.randint(0, l - buffer, size=batch_size)\n",
    "    end = start + seq_len\n",
    "    texts = [data[s:e] for s, e in zip(start, end)]\n",
    "    \n",
    "    encoded_texts = encode_arr(texts, max_seq_len=seq_len + 1)\n",
    "    targets = encoded_texts[:, 1:]\n",
    "    inputs = encoded_texts[:, :-1]\n",
    "    \n",
    "    targets = torch.tensor(targets, dtype=torch.long)\n",
    "    inputs = torch.tensor(inputs, dtype=torch.long)\n",
    "    \n",
    "    return inputs, targets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target is just x shifted one token to the left!\n",
      "x[0]: tensor([  0,  81,   8, 112,  37,  49,  21,  37,  31,  37,  47,  31,  79,  37,\n",
      "        100, 104,  49,  37,  97,  96,  37,  96,  89]),\n",
      "y[0] tensor([ 81,   8, 112,  37,  49,  21,  37,  31,  37,  47,  31,  79,  37, 100,\n",
      "        104,  49,  37,  97,  96,  37,  96,  89,   8])\n"
     ]
    }
   ],
   "source": [
    "x, y = get_data(train_data, 4, 23)\n",
    "print(\"target is just x shifted one token to the left!\")\n",
    "print(f\"x[0]: {x[0]},\\ny[0] {y[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNNs\n",
    "\n",
    "Now before modelling, let us look at a RNN layer and understand its input and outputs. Each RNN layer has the following basic archtecture: \n",
    "\n",
    "![unrolled RNN](rnn_unrolled.png){#fig-unrolled-rnn height=70%, width=70%}\n",
    "\n",
    "## Understanding RNNs\n",
    "\n",
    "RNNs have 2 matrices, one ($W_{xh}$) that maps input tokens to hidden_vector size and another ($W_{hh}$) that maps from hidden_vector to hidden_vector. You'll see how these are used in a minute. \n",
    "\n",
    "Let us first look at input-output shapes for an RNN layer. We initially had a batch of text-tokens. Lets assume batch size of 4 and max_seq_len of 32. Hence the shape of input is (4,32).\n",
    "\n",
    "Now for each token, we encode it to a number and then map it to a vector (which we generally call an embedding). Hence each token is now represented by a vector of fixed-shape, and lets call this embedding_dimension and set it to 10.\n",
    "(This can also be done by classical methods like one-hot encoding, ngram-models)\n",
    "\n",
    "The shape of our input batch is now (batch_size, max_seq_len, emb_dim), ie (4,32,10).\n",
    "\n",
    "Now let us peek into the matrix multiplications inside a RNN layer. \n",
    "Firstly, lets us recall that for a linear layer, this is the matrix equation: \n",
    "\n",
    "$z (N, n_{out}) = \\sigma(x (N, n_{in}) * W_x^T (n_{in}, n_{out}) + b (N))$\n",
    "\n",
    "where , \n",
    "\n",
    "- input-features = $n_{in}$\n",
    "- output-features = $n_{out}$\n",
    "- batch-size = $N$\n",
    "\n",
    "In a linear layer, each token/feature is attended to by a different weight in the weight matrix and no information is shared among the sequence tokens. But when processing \"sequences\" we obviously want the model to remember stuff from previous tokens for the current token, right?\n",
    "\n",
    "Hence RNNs maintain a hidden_vector for each token, that takes as input the current token and the hidden_vector from the previous token's output.\n",
    "\n",
    "So for the $t$'th token, \n",
    "\n",
    "$h_t (N, h)= x_t (N, n_{in}) * W_{xh}^T (n_{in}, h) + h_{t-1} (N, h) * W_{hh}^T (h, h) + biases$\n",
    "\n",
    "where \n",
    "\n",
    "- input-features = $n_{in}$\n",
    "- hidden-size = $h$\n",
    "- batch-size = $N$\n",
    "- sequence-length = $s$\n",
    "\n",
    "As you'll notice since each token depends on previous tokens output, we cannot process this parallelly and have to iteratively calculate the output for each token. Also note we generally refer to the different tokens in a sequence as different timesteps, ie token at timestep t is $x_t$.\n",
    "\n",
    "\n",
    "Hence for a complete batch, inputs are:\n",
    "\n",
    "- $X$ of shape $(N, s, n_{in})$\n",
    "- $h_0$ of shape $(N, h)$ (this is optional, if not given most libraries will initiate a $h_0$ of all zeros or random numbers)\n",
    "\n",
    "And outputs are:\n",
    "\n",
    "- hidden states of all timesteps, ie $H$ of shape $(N, s, h)$\n",
    "- last_hidden_state ie $h_n$ of shape $(N, h)$\n",
    "\n",
    "\n",
    "Note: sometimes you will see outputs of rnn fed into a linear layer like so,\n",
    "```python\n",
    "outputs, h_n = self.rnn(x)\n",
    "y = self.fc(outputs[:,-1,:])\n",
    "```\n",
    "\n",
    "Here `h_n` and `outputs[:,-1,:]` are the same thing. They both represent the last hidden state for the entire batch. (to make shapes equal use `h_n.squeeze()`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets verify the above by passing inputs to an rnn layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 8, hidden_size: 128, max_seq_len: 32, emb_dim: 128\n",
      "shape of initial input -> torch.Size([8, 32])\n",
      "post embedding; shape of input to RNN layer -> torch.Size([8, 32, 128])\n",
      "RNN output shapes -> torch.Size([8, 32, 128]), [torch.Size([8, 128])]\n"
     ]
    }
   ],
   "source": [
    "emb_dim = 128\n",
    "hidden_size = 128\n",
    "batch_size = 8\n",
    "max_seq_len = 32\n",
    "\n",
    "print(f\"batch_size: {batch_size}, hidden_size: {hidden_size}, max_seq_len: {max_seq_len}, emb_dim: {emb_dim}\")\n",
    "X,y = get_data(train_data, seq_len=max_seq_len, batch_size=batch_size)\n",
    "print(f\"shape of initial input -> {X.shape}\")\n",
    "\n",
    "emb_layer = nn.Embedding(num_embeddings=len(vocab), embedding_dim=emb_dim)\n",
    "rnn_layer = nn.RNN(input_size=emb_dim, hidden_size=hidden_size, batch_first=True, bidirectional=False, num_layers=1)\n",
    "\n",
    "X = emb_layer(X)\n",
    "print(f\"post embedding; shape of input to RNN layer -> {X.shape}\")\n",
    "h_0 = torch.randn(1, batch_size, hidden_size)\n",
    "outputs = rnn_layer(X, h_0)\n",
    "\n",
    "print(f\"RNN output shapes -> {outputs[0].shape}, {[outputs[1][i].shape for i in range(len(outputs[1]))]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Modelling \n",
    "\n",
    "Now let us build a model and train it. For starters we'll just use a [torch.nn.RNN](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html#torch.nn.RNN) layer to build the model and train it. Once we get the entire training and testing pipeline complete, we can come back and build the model from scratch. \n",
    "    \n",
    "### How exactly can we generate text though?\n",
    "\n",
    "We know we can get hidden states of the entire sequence as outputs from a rnn layer, but each hidden state $h_t$ has ponly seen information till timestep $t$. \n",
    "What we can do is this: \n",
    "\n",
    "- only use the last hidden state and feed it to a linear layer with output shape equal to size of vocabulary. \n",
    "- if softmax is applied on top of the linear layer's output, it turns raw logits into the probabilities for different tokens in our vocab. This can be done outside the forward function too.\n",
    "\n",
    "Now each input sequence gives us one output token ie $y_{t+1}$. then we can take the sequence from $1$ to $t+1$ and generate token $y_{t+2}$. \n",
    "\n",
    "### During Training\n",
    "\n",
    "To maximize training we can use all hidden state outputs instead of the last one. Because why wouldnt we want the model to learn from all its outputs!\n",
    "\n",
    "- output of rnn layer of shape $(N, s, h)$ is fed into a linear layer of shape $(h, vocab\\_size)$ to get $(N,s,vocab\\_size)$ outputs. then we can pass them via softmax and apply cross-entropy loss on all of them and backpropagate through the model.\n",
    "- since at token level we now have $N*s$ tokens on which we will calculate loss, its simpler to flatten the targets and generated logits before passing to cross-entropy loss.\n",
    "\n",
    "Note: Had it been a classification task, we could just pass last hidden_state, $h_n$ to a linear layer with output size equal to number of classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "# calculate size of model parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "class Rnn_model(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_size, max_seq_len, hidden_size, num_layers=1, vocab_size=None):\n",
    "        \"\"\"\n",
    "        Initializes the Rnn_model class.\n",
    "\n",
    "        Args:\n",
    "            embedding_size (int): The size of the embedding dimension.\n",
    "            max_seq_len (int): The maximum sequence length.\n",
    "            hidden_size (int): The size of the hidden state dimension.\n",
    "            num_layers (int, optional): The number of recurrent layers. Defaults to 1.\n",
    "            vocab_size (int, optional): The size of the vocabulary. Defaults to None.\n",
    "\n",
    "        \"\"\"\n",
    "        super(Rnn_model, self).__init__()\n",
    "\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.vocab_size = len(vocab) if vocab_size is None else vocab_size\n",
    "        self.embedding = nn.Embedding(num_embeddings=self.vocab_size, embedding_dim=embedding_size)\n",
    "        self.rnn = nn.LSTM(input_size=embedding_size, hidden_size=hidden_size, batch_first=True, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, len(vocab))\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=0)  # ignore pad token\n",
    "\n",
    "    def forward(self, x, targets=None):\n",
    "        \"\"\" \n",
    "        a forward pas thorugh the model.\n",
    "        x: input torch tensor (B,T,S)\n",
    "        targets: input targets (B,T,S)\n",
    "\n",
    "        Returns\n",
    "        (model output logits, loss)\n",
    "        \"\"\"\n",
    "        x = x[:, -self.max_seq_len:]\n",
    "        x = self.embedding(x)\n",
    "        H, h_n = self.rnn(x)\n",
    "\n",
    "        # y = self.fc(H[:,-1,:])\n",
    "        y = self.fc(H)\n",
    "        \n",
    "        if targets is not None:\n",
    "            B, T, V = y.shape\n",
    "            loss = self.criterion(y.view(B*T, V), targets.view(-1))\n",
    "        else: loss=None\n",
    "        \n",
    "        return y, loss\n",
    "    \n",
    "    \n",
    "    @torch.no_grad\n",
    "    def generate(self, input_text, max_len=32, device='cpu'):\n",
    "        \"\"\" \n",
    "        input_text: a string or list of strings to generate text using the model.\n",
    "        max_len: model will generate maximum of max_len tokens.\n",
    "        \"\"\"\n",
    "        \n",
    "        encoded_tokens = torch.tensor(encode_arr([input_text], max_seq_len=32))\n",
    "        if encoded_tokens.ndim == 1:\n",
    "            encoded_tokens = encoded_tokens.unsqueeze(0)\n",
    "\n",
    "        self = self.to(device)\n",
    "        encoded_tokens = encoded_tokens.to(device)\n",
    "        for i in range(max_len):\n",
    "            # only keep the most recent seq_len sized numbers.\n",
    "            outputs, _ = self(encoded_tokens[:, -self.max_seq_len:])\n",
    "\n",
    "            # last output token\n",
    "            outputs = outputs[:, -1, :]\n",
    "\n",
    "            # get pribabilities from logits\n",
    "            next_token_probs = nn.functional.softmax(outputs, dim=-1)\n",
    "\n",
    "            # sample indices from it using a multinomial distribution\n",
    "            next_tokens = torch.multinomial(next_token_probs, 1)\n",
    "\n",
    "            # concat prediction to original text\n",
    "            encoded_tokens = torch.concat((encoded_tokens, next_tokens), axis=1)\n",
    "\n",
    "        decoded_texts = decode_arr(encoded_tokens)\n",
    "        if len(decoded_texts)==1:\n",
    "            return decoded_texts[0] #.replace(\"<pad>\", \"\") \n",
    "        else: \n",
    "            # return [text.replace(\"<pad>\", \"\") for text in decoded_texts]\n",
    "            return decoded_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop\n",
    "\n",
    "Now I'll define a basic training loop to train this model, and we'll generate text every 1k steps to see the model learn right before us! Im also using tensorboard to log and view my runs. IMO its the best way to visualize loss curves and debug model behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paramter count of the model: 1114232, data_size: 2449724\n",
      "\n",
      "after 0 steps: \n",
      "prompt is: but I told him clearly, that if\n",
      "\n",
      "text generated by model: \n",
      "but I told him clearly, that ifâDaL—WX2m‘;D3æJqèup½’VDnJi^Rjje(lSïVcCrgWmMQSXA9W9`_Fî+E5l&1sVq\\6]=^fê—>804àâ!yñêI・y=6&l,{$Oû.1—u*$9‘KM!Oñ-cW’MéñhB~M.j6r{}xl\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "after 1000 steps: \n",
      "prompt is: but I told him clearly, that if\n",
      "\n",
      "text generated by model: \n",
      "but I told him clearly, that if\n",
      "Twen tracked of him grivel-napregred whotain one come,\n",
      "in hy midge withoush, which shoulquould before so speeded the feet in th\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "after 2000 steps: \n",
      "prompt is: but I told him clearly, that if\n",
      "\n",
      "text generated by model: \n",
      "but I told him clearly, that if still come, but I don’t know. Mc! So yester I shall five onnestible, “that peired, want and\n",
      "asfected to his harded has\n",
      "Farching\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "after 3000 steps: \n",
      "prompt is: but I told him clearly, that if\n",
      "\n",
      "text generated by model: \n",
      "but I told him clearly, that ifner, for sheep there indobless.\n",
      "And Holmes\n",
      "when we start the once.”\n",
      "\n",
      "“Thanks between rouse vrisings of as one of\n",
      "firied presing,\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "after 4000 steps: \n",
      "prompt is: but I told him clearly, that if\n",
      "\n",
      "text generated by model: \n",
      "but I told him clearly, that if you had a explain and after we like it. He is every are that the main that in a valued her this example in our myselture for th\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "after 5000 steps: \n",
      "prompt is: but I told him clearly, that if\n",
      "\n",
      "text generated by model: \n",
      "but I told him clearly, that if yim you have helpered befored. Therest name It\n",
      "famousore, that he sat three\n",
      "      it, and he said that we met him earsh back in\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "after 6000 steps: \n",
      "prompt is: but I told him clearly, that if\n",
      "\n",
      "text generated by model: \n",
      "but I told him clearly, that if I can\n",
      "started which he came many way heir imperiable takely room. A now,\n",
      "      “What was only fancy,” he was a gentleman concei\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "after 7000 steps: \n",
      "prompt is: but I told him clearly, that if\n",
      "\n",
      "text generated by model: \n",
      "but I told him clearly, that if your mistaken, and yet use_ the\n",
      "Close of Baskerville, is obvious fashions and left your\n",
      "brusticion of the longly seat from this\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "after 8000 steps: \n",
      "prompt is: but I told him clearly, that if\n",
      "\n",
      "text generated by model: \n",
      "but I told him clearly, that if I’d fain the\n",
      "others.”\n",
      "\n",
      "“How made you, Watson, he was demilent? With past as another? One enemal with fift me out and was art vi\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "after 9000 steps: \n",
      "prompt is: but I told him clearly, that if\n",
      "\n",
      "text generated by model: \n",
      "but I told him clearly, that if I do follow made the owns\n",
      "behind these common understand that is I, and they may not cast\n",
      "occurred to suggest we idea?”\n",
      "\n",
      "“Not r\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "after 9999 steps: \n",
      "prompt is: but I told him clearly, that if\n",
      "\n",
      "text generated by model: \n",
      "but I told him clearly, that if if I was able faintled back in the hand, air which had\n",
      "dirmanscoctors way. That’s close.\n",
      "\n",
      "“Does_ gone. I recond feare, and that\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "[4.787812232971191, 1.8653450012207031, 1.7018814086914062, 1.655837059020996, 1.5209026336669922, 1.5495105981826782, 1.5696816444396973, 1.560757040977478, 1.5683640241622925, 1.4509146213531494, 1.4306949377059937, 1.4603841304779053, 1.3696606159210205, 1.5044567584991455, 1.3786689043045044, 1.3815288543701172, 1.3697071075439453]\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: false\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('./runs/with_gradients/')\n",
    "\n",
    "NUM_STEPS = 10000\n",
    "MAX_SEQ_LEN = 32\n",
    "BATCH_SIZE = 32\n",
    "EMBEDDING_SIZE = 256\n",
    "HIDDEN_SIZE = 256\n",
    "NUM_LAYERS = 2\n",
    "LR = 0.001 \n",
    "LOG_EVERY = 200\n",
    "GENERATE_EVERY = 1000\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_built() else \"cpu\")\n",
    "\n",
    "model = Rnn_model(embedding_size=EMBEDDING_SIZE, max_seq_len=MAX_SEQ_LEN, hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS)\n",
    "print(f\"paramter count of the model: {count_parameters(model)}, data_size: {len(train_data)}\\n\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "losses = []\n",
    "for i in (range(NUM_STEPS)):\n",
    "    optimizer.zero_grad()\n",
    "    x, y = get_data(train_data, BATCH_SIZE, MAX_SEQ_LEN)\n",
    "    \n",
    "    model.to(device)\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    outputs, loss = model(x, y)\n",
    "    loss.backward()\n",
    "\n",
    "    # clip gradients\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "    # Log gradients before the optimization step\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.grad is not None:\n",
    "            writer.add_histogram(f'gradients/{name}', param.grad, i)\n",
    "\n",
    "    optimizer.step()\n",
    "    if i%LOG_EVERY==0:\n",
    "        losses.append(loss)\n",
    "        # print(loss.item())\n",
    "    \n",
    "    writer.add_scalar('Loss/train', loss.item(), i)\n",
    "\n",
    "    \n",
    "    if i%GENERATE_EVERY==0 or i==NUM_STEPS-1:\n",
    "        print(f\"after {i} steps: \")\n",
    "        prompt = 'but I told him clearly, that if'\n",
    "        print(f\"prompt is: {prompt}\")\n",
    "        gen_text = model.generate(prompt, max_len=128)\n",
    "        gen_text = gen_text.replace(\"<pad>\", \"\")\n",
    "        print(f\"\\ntext generated by model: \\n{gen_text}\\n\")\n",
    "        print('-'*75)\n",
    "        \n",
    "\n",
    "writer.close()\n",
    "\n",
    "losses = [loss.cpu().detach().numpy().item() for loss in losses] \n",
    "# print(losses[::3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot losses\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results certainly improve over the iterations, and its clearly visible that the model is learning to generate text. By scaling the model and training for longer, we can get better results. \n",
    "\n",
    "Thank you for reading this and I hope you found it useful. The next time I update this blog post, I'll be adding the following:\n",
    "\n",
    "- Evaluation on test set (metrics like perplexity).\n",
    "- Implementing RNN, LSTM and GRU from scratch.\n",
    "\n",
    "Byee :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!---\n",
    "- sqitching from SGD to adam instantly gives boost (2.8 vs under 2)\n",
    "- tripling the data gave no gains on 50k basic rnn model!\n",
    "- 300k characters seems enough to generate coherent text, why not happening here?\n",
    "    - lets try a few things, take small corpus (2-3mil chars), <1 million param model and use techiques like grad-clipping, mps on mac local(faster), and see if we can get it to generate coherent text.\n",
    "    - mps reduces training-time by more than half.\n",
    "    - grad clipping doesnt seem to affect quality on inspection of generated text.\n",
    "\n",
    "- logging to tensorboard to keep track of experiments and to visualize gradients too. (X-ray vision)\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!---\n",
    "#### 100k rnn model - 3million chars: ~1.5 loss, kinda starts to form words\n",
    "outputs:\n",
    "1. hey there handsome what death which are a discroose.”\n",
    "2. I recall went small-boy’s Louded spoke. T\n",
    "\n",
    "\n",
    "#### 100k rnn model - 12million chars: ~1.6 loss, similar \n",
    "1. hey there handsome what\n",
    "to on?”\n",
    "\n",
    "Midams: I lady of\n",
    "quiked in her put intented to the burgent wonder the risons of the saw\n",
    "      four spikely. To belled\n",
    "2. I recall Katerinoad and sure\n",
    "conforty, unsole only geitute and, and it stigged refundled as a\n",
    "  was abserved. Every tran at you.”\n",
    "\n",
    "THO\"Ci\n",
    "\n",
    "#### 330k lstm model - 12million chars: ~ 1.52 loss, \n",
    "1. hey there handsome what?” are that indid of nebvense of the Samiskamen theory instance Loins, fry committed, or suggested fagreedingly.\n",
    "\n",
    "Judge Stannaph\n",
    "2. I recall are that any quality shall, as the man\n",
    "been unknight, in his\n",
    "closkered. The common as though sad so'll he had she askoccite\n",
    "    \n",
    "#### 1million lstm model - 3million chars: ~1.4 loss, 10k steps \n",
    "paramter count of the model: 1114232, 3million chars  \n",
    "\n",
    "text generated by model after 0 steps of training but I told him clearly, that ifVOS£QY^DêX£véF LD[sœPyZê$t½’sXz<nf#t0|%çIw<à’\"n・ê+r^êi?\\fZâEl@K\n",
    "Yu%@3VâZJ}_}$B` àl・à$rï:hàNBbZ0j½~6#û8vàC/[Vn$KRéüylyhê|.ûî&EJ2I\n",
    "\n",
    "\n",
    "text generated by model after 1000 steps of training but I told him clearly, that if the bet’s of the\n",
    "      yecraiuply that deen-tated for langent\n",
    "pasts with! I was a tedeter.”\n",
    "       I at, encurned. A, my dook a\n",
    "\n",
    "\n",
    "text generated by model after 2000 steps of training but I told him clearly, that if he reabsa deed some\n",
    "seard us a heard his nevriept took’h myself and come against is need of Eaker, and terrised a clearly enoye\n",
    "\n",
    "\n",
    "text generated by model after 3000 steps of training but I told him clearly, that if Right\n",
    "then, who roronian had monting that I must settating you passion. Fut us contain him thion. Amy taken\n",
    "and to sympent-litt\n",
    "\n",
    "\n",
    "text generated by model after 4000 steps of training but I told him clearly, that if ears whet a\n",
    "your smalls friend\n",
    "      so.”\n",
    "\n",
    "“And you? Scotling us in the ensetate on the stappered. “A stors, but which I work w\n",
    "\n",
    "\n",
    "text generated by model after 5000 steps of training but I told him clearly, that if be whose give anches was for me to his many\n",
    "wears the anyone? The back down of brought than answered, sir; “Sudden horror and c\n",
    "\n",
    "\n",
    "text generated by model after 6000 steps of training but I told him clearly, that if he had telegreas.”\n",
    "\n",
    "“Why I knew I have been examed.”\n",
    "\n",
    "“Certails, he spetter lodge oppon the next opportmend in I. I skined it, \n",
    "\n",
    "\n",
    "text generated by model after 7000 steps of training but I told him clearly, that if the Dark, sharp_ and that\n",
    "their repaudance with us a fearer with a largue down, “but the live night, Murch-Starter reading upon\n",
    "\n",
    "\n",
    "text generated by model after 8000 steps of training but I told him clearly, that if you will\n",
    "opens but I year?” said he. “That is near that shifted as into the canner life came.—This warning\n",
    "friend that I had ca\n",
    "\n",
    "\n",
    "text generated by model after 9000 steps of training but I told him clearly, that if I trauntion, that they are note too vellering keep of\n",
    "their part, and there was help being upon us the whole was snicks when?”\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1. OG blog by Karpathy [link](https://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "2. RNN torch documentation [link](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html#torch.nn.RNN)\n",
    "3. Karpathy 1hr lecture on recurennt networks [link](https://www.youtube.com/watch?v=yCC09vCHzF8)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arxiv",
   "language": "python",
   "name": "arxiv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
