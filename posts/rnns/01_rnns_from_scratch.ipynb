{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "#| eval: falseq\n",
    "# %load_ext autoreload \n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Language Modelling with RNNS\"\n",
    "author: Deepam Minda\n",
    "date: \"July 20, 2024\"\n",
    "categories: [rnns, nlp, seq-to-seq, langauge-modelling]\n",
    "format:\n",
    "  html:\n",
    "    toc: true\n",
    "    toc-depth: 3\n",
    "    html-math-method: katex\n",
    "    code-fold: true\n",
    "    code-summary: \"show code\"\n",
    "    highlight-style: github\n",
    "execute:\n",
    "  warning: false\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The only reason you would be hearing RNNs right now is probably when [xLSTMs](https://arxiv.org/pdf/2405.04517) were released in May, 2024. Apart from this they have pretty much taken a back seat to watch transformers revolutionalize NLP and the entire field of AI in general. \n",
    "\n",
    "But one would do well to remember how we got here, and RNNs played a massive role in bringing us here. So in this blog post I'm going to build a small RNN model and we'll try to train it to generate text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data and process it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us load a text dataset. I downloaded a few mystery books and concatenated their raw text to make the dataset. Follow [this](https://github.com/mindadeepam/mindadeepam.github.io/blob/posts/posts/rnns/corpus.txt) link to get the text file. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "dataset_path = \"./corpus.txt\"\n",
    "\n",
    "with open(dataset_path, 'r') as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look at some of the text we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data chunk:\n",
      "'rld has seen, but as a lover he would have placed himself in a\n",
      "false position. He never spoke of the softer passions, save with a gibe\n",
      "and a sneer. They were admirable things for the observer—excellent for\n",
      "drawing the veil from men’s motives and actions. But for the trained\n",
      "reasoner to admit such intrusions into his own delicate and finely\n",
      "adjusted temperament was to introduce a distracting factor which might\n",
      "throw a doubt upon all his mental results. Grit in a sensitive\n",
      "instrument, or a crack i'\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sample data chunk:\\n'{data[1000:1500]}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets split the data into train and test (80-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size: 2449724, test_size: 612431  (in number of tokens)\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(data) * 0.8)\n",
    "train_data, test_data = data[:train_size], data[train_size:]\n",
    "\n",
    "print(f\"train_size: {len(train_data)}, test_size: {len(test_data)}  (in number of tokens)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us encode the text to numerical data that our model can understand. Encoding the data generally means tokenization and then encoding. To keep it super simple, we'll just use individual characters as tokens.\n",
    "\n",
    "Nowadays however, subword [tokenization algorithms]((https://huggingface.co/docs/transformers/main/en/tokenizer_summary)) like Byte-Pair Encoding are the norm. But let us not get caught up in those for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "# Define the vocabulary and special tokens\n",
    "vocab = list(set(train_data+\"12345678910qwertyuioplkjhgfdsamnbvcxz~!@#$%^&*()_+`-=[];'./,{}\\\":?><\\|\"))\n",
    "PAD_TOKEN = '<pad>'\n",
    "special_tokens = [PAD_TOKEN]\n",
    "MAX_SEQ_LEN = 32\n",
    "\n",
    "vocab = [*special_tokens, *vocab]\n",
    "\n",
    "# Create mappings for encoding and decoding\n",
    "decode_mapping = dict(enumerate(vocab))\n",
    "encode_mapping = {v:k for k,v in decode_mapping.items()}\n",
    "\n",
    "# Define encoding and decoding functions\n",
    "encode = lambda text: [encode_mapping[char] for char in text]\n",
    "decode = lambda text: [decode_mapping[char] for char in text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can do a simple sanity check by encoding a text and decoding it. we should get the original string back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original text: hey there\n",
      "tokenized text: ['h', 'e', 'y', ' ', 't', 'h', 'e', 'r', 'e']\n",
      "encoded text: [74, 66, 31, 53, 104, 74, 66, 24, 66]\n",
      "decoded back:['h', 'e', 'y', ' ', 't', 'h', 'e', 'r', 'e']\n"
     ]
    }
   ],
   "source": [
    "text = \"hey there\"\n",
    "encoded_text = encode(text)\n",
    "\n",
    "print(f\"original text: {text}\")\n",
    "print(f\"tokenized text: {list(text)}\")\n",
    "print(f'encoded text: {encoded_text}')\n",
    "print(f\"decoded back:{decode(encoded_text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need functions that will do this for batches of texts rather than single text. \n",
    "When dealing with batches, there are a few extra considerations: \n",
    "- You would typically want your batches to contain texts which are of same length, so that matrix/tensor operations can be performed. Hence we need to truncate longer sentences and pad shorter sentences to a fixed length.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "#| code-fold: false\n",
    "\n",
    "def tokenize_arr(texts, max_seq_len=256):\n",
    "    \"\"\"\n",
    "    Tokenizes a list of texts and returns the tokenized array.\n",
    "\n",
    "    Args:\n",
    "        texts (list): A list of texts to be tokenized.\n",
    "        max_seq_len (int, optional): The maximum sequence length. Defaults to 256.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The tokenized array.\n",
    "\n",
    "    \"\"\"\n",
    "    # texts = pad_texts(texts, max_seq_len=MAX_SEQ_LEN)\n",
    "    texts = np.array(texts).reshape(-1,1)\n",
    "\n",
    "    texts = [list(doc) for text in texts for doc in text]\n",
    "    for i, text in enumerate(texts):\n",
    "        if len(text)>max_seq_len:\n",
    "            texts[i] = text[:max_seq_len]\n",
    "        elif len(text)<max_seq_len:\n",
    "            num_pad_tokens = max_seq_len-len(text)\n",
    "            texts[i] = [*([PAD_TOKEN]*num_pad_tokens) + text]\n",
    "    \n",
    "    return np.array(texts)\n",
    "\n",
    "def encode_arr(texts, encode_mapping=encode_mapping, max_seq_len=MAX_SEQ_LEN):\n",
    "    \"\"\"\n",
    "    Encodes an array of texts using a given encoding mapping.\n",
    "\n",
    "    Args:\n",
    "        texts (numpy.ndarray): The array of texts to be encoded.\n",
    "        encode_mapping (dict): A dictionary mapping characters to their corresponding encodings.\n",
    "        max_seq_len (int): The maximum sequence length.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The encoded texts.\n",
    "\n",
    "    \"\"\"\n",
    "    texts = tokenize_arr(texts, max_seq_len)\n",
    "    # print(texts)\n",
    "    texts = np.apply_along_axis(lambda text: [encode_mapping.get(x) for x in text], arr=texts, axis=1)\n",
    "    return texts.squeeze()\n",
    "\n",
    "def decode_arr(texts):\n",
    "    \"\"\"\n",
    "    Decodes a list of encoded texts using a decoding mapping.\n",
    "    \n",
    "    Parameters:\n",
    "    texts (numpy.ndarray): A numpy array of encoded texts.\n",
    "    \n",
    "    Returns:\n",
    "    list: A list of decoded texts.\n",
    "    \"\"\"\n",
    "    decoded_texts = np.apply_along_axis(lambda text: ([decode_mapping[x] for x in text]), arr=texts, axis=1)\n",
    "    decoded_texts = decoded_texts.tolist()\n",
    "    decoded_texts = [\"\".join(text) for text in decoded_texts]\n",
    "    return decoded_texts\n",
    "\n",
    "\n",
    "texts = [['hey there', \"talk much\", \"kendirck is cool af\"]]\n",
    "encoded_texts = encode_arr(texts)\n",
    "decoded_texts = decode_arr(encoded_texts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity let us also define a function that will fetch us a random batch of data from our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "def get_data(data, batch_size=16, seq_len=256):\n",
    "    \"\"\"\n",
    "    Retrieves input and target data for training a recurrent neural network (RNN).\n",
    "\n",
    "    Args:\n",
    "        data (list): The input data.\n",
    "        batch_size (int, optional): The number of sequences in each batch. Defaults to 16.\n",
    "        seq_len (int, optional): The length of each sequence. Defaults to 256.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the input and target data tensors.\n",
    "            - inputs (torch.Tensor): The input data tensor.\n",
    "            - targets (torch.Tensor): The target data tensor.\n",
    "    \"\"\"\n",
    "    buffer = 1000\n",
    "    l = len(data)\n",
    "    start = np.random.randint(0, l - buffer, size=batch_size)\n",
    "    end = start + seq_len\n",
    "    texts = [data[s:e] for s, e in zip(start, end)]\n",
    "    \n",
    "    encoded_texts = encode_arr(texts, max_seq_len=seq_len + 1)\n",
    "    targets = encoded_texts[:, 1:]\n",
    "    inputs = encoded_texts[:, :-1]\n",
    "    \n",
    "    targets = torch.tensor(targets, dtype=torch.long)\n",
    "    inputs = torch.tensor(inputs, dtype=torch.long)\n",
    "    \n",
    "    return inputs, targets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target is just x shifted one token to the left!\n",
      "x[0]: tensor([  0,  53, 104,  74,  48,  26,  45,  74, 104,  53,  17,  66,  24,  74,\n",
      "         47,  17,  80,  94,  53,  53,  53,  53,  53]),\n",
      "y[0] tensor([ 53, 104,  74,  48,  26,  45,  74, 104,  53,  17,  66,  24,  74,  47,\n",
      "         17,  80,  94,  53,  53,  53,  53,  53,  53])\n"
     ]
    }
   ],
   "source": [
    "x, y = get_data(train_data, 4, 23)\n",
    "print(\"target is just x shifted one token to the left!\")\n",
    "print(f\"x[0]: {x[0]},\\ny[0] {y[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNNS\n",
    "\n",
    "Now before modelling, let us look at a RNN layer and understand its input and outputs. Each RNN layer has the following basic archtecture: \n",
    "\n",
    "![unrolled RNN](rnn_unrolled.png){#fig-unrolled-rnn height=70%, width=70%}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding RNNs\n",
    "\n",
    "RNNs have 2 matrices, one ($W_{xh}$) that maps input tokens to hidden_vector size and another ($W_{hh}$) that maps from hidden_vector to hidden_vector. You'll see how these are used in a minute. \n",
    "\n",
    "Let us first look at input-output shapes for an RNN layer. We initially had a batch of text-tokens. Lets assume batch size of 4 and max_seq_len of 32. Hence the shape of input is (4,32).\n",
    "\n",
    "Now for each token, we encode it to a number and then map it to a vector (which we generally call an embedding). Hence each token is now represented by a vector of fixed-shape, and lets call this embedding_dimension and set it to 10.\n",
    "\n",
    "The shape of our input batch is now (batch_size, max_seq_len, emb_dim), ie (4,32,10).\n",
    "\n",
    "Now let us peek into the matrix multiplications inside a RNN layer. \n",
    "Firstly, lets us recall that for a linear layer, this is the matrix equation: \n",
    "\n",
    "$z (N, n_{out}) = \\sigma(x (N, n_{in}) * W_x^T (n_{in}, n_{out}) + b (N))$\n",
    "\n",
    "where , \n",
    "\n",
    "- input-features = $n_{in}$\n",
    "- output-features = $n_{out}$\n",
    "- batch-size = $N$\n",
    "\n",
    "In a linear layer, each token/feature is attended to by a different weight in the weight matrix and no information is shared among the sequence tokens. But when processing \"sequences\" we obviously want the model to remember stuff from previous tokens for the current token, right?\n",
    "\n",
    "Hence RNNs maintain a hidden_vector for each token, that takes as input the current token and the hidden_vector from the previous token's output.\n",
    "\n",
    "So for the $t$'th token, \n",
    "\n",
    "$h_t (N, h)= x_t (N, n_{in}) * W_{xh}^T (n_{in}, h) + h_{t-1} (N, h) * W_{hh}^T (h, h) + biases$\n",
    "\n",
    "where \n",
    "\n",
    "- input-features = $n_{in}$\n",
    "- hidden-size = $h$\n",
    "- batch-size = $N$\n",
    "- sequence-length = $s$\n",
    "\n",
    "As you'll notice since each token depends on previous tokens output, we cannot process this parallelly and have to iteratively calculate the output for each token. Also note we generally refer to the different tokens in a sequence as different timesteps, ie token at timestep t is $x_t$.\n",
    "\n",
    "\n",
    "Hence for a complete batch, inputs are:\n",
    "\n",
    "- $X$ of shape $(N, s, n_{in})$\n",
    "- $h_0$ of shape $(N, h)$ (this is optional, if not given most libraries will initiate a $h_0$ of all zeros or random numbers)\n",
    "\n",
    "And outputs are:\n",
    "\n",
    "- hidden states of all timesteps, ie $H$ of shape $(N, s, h)$\n",
    "- last_hidden_state ie $h_n$ of shape $(N, h)$\n",
    "\n",
    "\n",
    "Note: sometimes you will see outputs of rnn fed into a linear layer like so,\n",
    "```python\n",
    "outputs, h_n = self.rnn(x)\n",
    "y = self.fc(outputs[:,-1,:])\n",
    "```\n",
    "\n",
    "Here `h_n` and `outputs[:,-1,:]` are the same thing. They both represent the last hidden state for the entire batch. (to make shapes equal use `h_n.squeeze()`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets verify the above by passing inputs to an rnn layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 4, hidden_size: 100, max_seq_len: 256, emb_dim: 50\n",
      "shape of initial input -> torch.Size([4, 256])\n",
      "post embedding; shape of input to RNN layer -> torch.Size([4, 256, 50])\n",
      "RNN output shapes -> torch.Size([4, 256, 100]), [torch.Size([4, 100])]\n"
     ]
    }
   ],
   "source": [
    "emb_dim = 50\n",
    "hidden_size = 100\n",
    "batch_size = 4\n",
    "max_seq_len = 256\n",
    "\n",
    "print(f\"batch_size: {batch_size}, hidden_size: {hidden_size}, max_seq_len: {max_seq_len}, emb_dim: {emb_dim}\")\n",
    "X,y = get_data(train_data, seq_len=max_seq_len, batch_size=batch_size)\n",
    "print(f\"shape of initial input -> {X.shape}\")\n",
    "\n",
    "emb_layer = nn.Embedding(num_embeddings=len(vocab), embedding_dim=emb_dim)\n",
    "rnn_layer = nn.RNN(input_size=emb_dim, hidden_size=hidden_size, batch_first=True, bidirectional=False, num_layers=1)\n",
    "\n",
    "X = emb_layer(X)\n",
    "print(f\"post embedding; shape of input to RNN layer -> {X.shape}\")\n",
    "h_0 = torch.randn(1, batch_size, hidden_size)\n",
    "outputs = rnn_layer(X, h_0)\n",
    "\n",
    "print(f\"RNN output shapes -> {outputs[0].shape}, {[outputs[1][i].shape for i in range(len(outputs[1]))]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Modelling \n",
    "\n",
    "Now let us build a model and train it. For starters we'll just use a [torch.nn.RNN](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html#torch.nn.RNN) layer to build the model and train it. Once we get the entire training and testing pipeline complete, we can come back and build the model from scratch. \n",
    "    \n",
    "### How exactly can we generate text though?\n",
    "\n",
    "We know we can get hidden states of the entire sequence as outputs from a rnn layer, but each hidden state $h_t$ has ponly seen information till timestep $t$. \n",
    "What we can do is this: \n",
    "\n",
    "- only use the last hidden state and feed it to a linear layer with output shape equal to size of vocabulary. \n",
    "- if softmax is applied on top of the linear layer's output, it turns raw logits into the probabilities for different tokens in our vocab. This can be done outside the forward function too.\n",
    "\n",
    "Now each input sequence gives us one output token ie $y_{t+1}$. then we can take the sequence from $1$ to $t+1$ and generate token $y_{t+2}$. \n",
    "\n",
    "### During Training\n",
    "\n",
    "To maximize training we can use all hidden state outputs instead of the last one. Because why wouldnt we want the model to learn from all its outputs!\n",
    "\n",
    "- output of rnn layer of shape $(N, s, h)$ is fed into a linear layer of shape $(h, vocab\\_size)$ to get $(N,s,vocab\\_size)$ outputs. then we can pass them via softmax and apply cross-entropy loss on all of them and backpropagate through the model.\n",
    "- since at token level we now have $N*s$ tokens on which we will calculate loss, its simpler to flatten the targets and generated logits before passing to cross-entropy loss.\n",
    "\n",
    "Note: Had it been a classification task, we could just pass last hidden_state, $h_n$ to a linear layer with output size equal to number of classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "class Rnn_model(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_size, max_seq_len, hidden_size, num_layers=1, vocab_size=None):\n",
    "        \"\"\"\n",
    "        Initializes the Rnn_model class.\n",
    "\n",
    "        Args:\n",
    "            embedding_size (int): The size of the embedding dimension.\n",
    "            max_seq_len (int): The maximum sequence length.\n",
    "            hidden_size (int): The size of the hidden state dimension.\n",
    "            num_layers (int, optional): The number of recurrent layers. Defaults to 1.\n",
    "            vocab_size (int, optional): The size of the vocabulary. Defaults to None.\n",
    "\n",
    "        \"\"\"\n",
    "        super(Rnn_model, self).__init__()\n",
    "\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.vocab_size = len(vocab) if vocab_size is None else vocab_size\n",
    "        self.embedding = nn.Embedding(num_embeddings=self.vocab_size, embedding_dim=embedding_size)\n",
    "        self.rnn = nn.RNN(input_size=embedding_size, hidden_size=hidden_size, batch_first=True, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, len(vocab))\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=0)  # ignore pad token\n",
    "\n",
    "    def forward(self, x, targets=None):\n",
    "        \"\"\" \n",
    "        a forward pas thorugh the model.\n",
    "        x: input torch tensor (B,T,S)\n",
    "        targets: input targets (B,T,S)\n",
    "\n",
    "        Returns\n",
    "        (model output logits, loss)\n",
    "        \"\"\"\n",
    "        x = x[:, -self.max_seq_len:]\n",
    "        x = self.embedding(x)\n",
    "        H, h_n = self.rnn(x)\n",
    "\n",
    "        # y = self.fc(H[:,-1,:])\n",
    "        y = self.fc(H)\n",
    "        \n",
    "        if targets is not None:\n",
    "            B, T, V = y.shape\n",
    "            loss = self.criterion(y.view(B*T, V), targets.view(-1))\n",
    "        else: loss=None\n",
    "        \n",
    "        return y, loss\n",
    "    \n",
    "    \n",
    "    @torch.no_grad\n",
    "    def generate(self, input_text, max_len=32):\n",
    "        \"\"\" \n",
    "        input_text: a string or list of strings to generate text using the model.\n",
    "        max_len: model will generate maximum of max_len tokens.\n",
    "        \"\"\"\n",
    "        encoded_tokens = torch.tensor(encode_arr([input_text], max_seq_len=32))\n",
    "        if encoded_tokens.ndim == 1:\n",
    "            encoded_tokens = encoded_tokens.unsqueeze(0)\n",
    "\n",
    "        for i in range(max_len):\n",
    "            outputs, _ = self(encoded_tokens[:, -self.max_seq_len:])\n",
    "\n",
    "            # last output token\n",
    "            outputs = outputs[:, -1, :]\n",
    "\n",
    "            # get pribabilities from logits\n",
    "            next_token_probs = nn.functional.softmax(outputs, dim=-1)\n",
    "\n",
    "            # sample indices from it using a multinomial distribution\n",
    "            next_tokens = torch.multinomial(next_token_probs, 1)\n",
    "\n",
    "            # concat prediction to original text\n",
    "            encoded_tokens = torch.concat((encoded_tokens, next_tokens), axis=1)\n",
    "\n",
    "        decoded_texts = decode_arr(encoded_tokens)\n",
    "        if len(decoded_texts)==1:\n",
    "            return decoded_texts[0] #.replace(\"<pad>\", \"\") \n",
    "        else: \n",
    "            # return [text.replace(\"<pad>\", \"\") for text in decoded_texts]\n",
    "            return decoded_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Rnn_model(embedding_size=10, max_seq_len=32, hidden_size=20, num_layers=1)\n",
    "# x, y = get_data(train_data, 4, 32)\n",
    "# y_hat, loss = model(x)\n",
    "# x.shape, y.shape\n",
    "\n",
    "# print(y.shape, y_hat.shape)\n",
    "# # y = y.view(-1)\n",
    "# B, T, V = y_hat.shape\n",
    "# y_hat.view(B*T, V)\n",
    "\n",
    "# loss = nn.CrossEntropyLoss(ignore_index=0)\n",
    "# loss(y_hat.view(B*T, V), y.view(-1))\n",
    "# # loss(y_hat, y)\n",
    "# # y.shape, y_hat.shape\n",
    "\n",
    "\n",
    "# input_text = [\"whats up my G GGGGG\", \"hey there\"]\n",
    "# max_seq_len=32\n",
    "# encoded_tokens = torch.tensor(encode_arr([input_text], max_seq_len=max_seq_len))\n",
    "# print(encoded_tokens)\n",
    "# if encoded_tokens.ndim == 1:\n",
    "#     encoded_tokens = encoded_tokens.unsqueeze(0)\n",
    "\n",
    "# for i in range(4):\n",
    "#     print(encoded_tokens.shape, encoded_tokens[:, -max_seq_len:].shape)\n",
    "#     outputs = model(encoded_tokens[:, -max_seq_len:])\n",
    "#     # last output token\n",
    "#     next_token_probs = outputs[:, -1, :]\n",
    "#     # print(next_token_probs)\n",
    "#     # sample indices from it using a multinomial distribution\n",
    "#     next_tokens = torch.multinomial(next_token_probs, 1)\n",
    "#     # print(next_tokens)\n",
    "#     encoded_tokens = torch.concat((encoded_tokens, next_tokens), axis=1)\n",
    "\n",
    "# print(encoded_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.754984378814697, 2.9505343437194824, 2.4850621223449707, 2.314824104309082, 2.132694721221924, 2.0362727642059326, 2.0536997318267822]\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "NUM_STEPS = 1000\n",
    "MAX_SEQ_LEN = 64\n",
    "BATCH_SIZE = 32\n",
    "EMBEDDING_SIZE = 20\n",
    "HIDDEN_SIZE = 50\n",
    "NUM_LAYERS = 2\n",
    "LR = 0.001 \n",
    "log_every = 50\n",
    "\n",
    "model = Rnn_model(embedding_size=EMBEDDING_SIZE, max_seq_len=MAX_SEQ_LEN, hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "losses = []\n",
    "for i in range(NUM_STEPS):\n",
    "    optimizer.zero_grad()\n",
    "    x, y = get_data(train_data, BATCH_SIZE, MAX_SEQ_LEN)\n",
    "    outputs, loss = model(x, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i%log_every==0:\n",
    "        losses.append(loss)\n",
    "\n",
    "losses = [loss.detach().numpy().item() for loss in losses] \n",
    "print(losses[::3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot losses\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sqitching from SGD to adam instantly gives boost (2.8 vs under 2)\n",
    "- tripling the data gave no gains on 50k basic rnn model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at some outputs from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey there handsome what you reoth the that the beive do\n",
      "I recall the sroad tood oulf the inlow hi\n"
     ]
    }
   ],
   "source": [
    "#|code-fold: false\n",
    "for line in model.generate([\"hey there handsome what\", \"I recall \"]):\n",
    "    print(line.replace(\"<pad>\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paramter count of the model: 43320\n"
     ]
    }
   ],
   "source": [
    "# calculate size of model parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"paramter count of the model: {count_parameters(model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results dont make much sense, but the model is learning to generate text. By scaling the model and training for longer, we can get better results.\n",
    "\n",
    "Thank you for reading this and I hope you found it useful. The next time I update this blog post, I'll be adding the following:\n",
    "\n",
    "- Evaluation on test set (metrics like perplexity).\n",
    "- Implementing RNN, LSTM and GRU from scratch.\n",
    "\n",
    "Byee :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1. [OG blog by Karpathy](https://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "2. [RNN torch documentation](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html#torch.nn.RNN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arxiv",
   "language": "python",
   "name": "arxiv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
