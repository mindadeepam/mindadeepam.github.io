<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.53">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Deepam Minda">
<meta name="dcterms.date" content="2024-08-10">

<title>Training a Resnet in Pytorch – deepamminda</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">deepamminda</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About Me</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../blog.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../links.html"> 
<span class="menu-text">Links</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/mindadeepam"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/mindadeepam"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Training a Resnet in Pytorch</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">cnns</div>
                <div class="quarto-category">deep-learning</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Deepam Minda </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">August 10, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#vggs" id="toc-vggs" class="nav-link" data-scroll-target="#vggs">VGGs</a>
  <ul class="collapse">
  <li><a href="#convrelu-layer" id="toc-convrelu-layer" class="nav-link" data-scroll-target="#convrelu-layer">ConvReLU Layer</a></li>
  <li><a href="#block-of-convrelu-layers" id="toc-block-of-convrelu-layers" class="nav-link" data-scroll-target="#block-of-convrelu-layers">Block of ConvReLU layers</a></li>
  <li><a href="#vgg-model" id="toc-vgg-model" class="nav-link" data-scroll-target="#vgg-model">VGG model</a>
  <ul class="collapse">
  <li><a href="#computational-considerations" id="toc-computational-considerations" class="nav-link" data-scroll-target="#computational-considerations">computational considerations</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#inception" id="toc-inception" class="nav-link" data-scroll-target="#inception">Inception</a></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="01_resnet.out.ipynb" download="01_resnet.out.ipynb"><i class="bi bi-journal-code"></i>Jupyter</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>In my last post <a href="../../posts/cnns/00_cnn_basics.html">Intro to CNNs</a>, we discussed the basics of CNNs and how to train a simple CNN from scratch. In this post, we will train a ResNet in Pytorch.</p>
<p>Resnets came around right after VGGs, where the author explored the idea of training very deep networks for better performance, since deeper models could in thoery learn more complex features. But after a certain point, more depth didnt help with wither validation accuracy nor training performance. This was confusing, since we would assume a larger model can atleast replicate the performance of a smaller network and then some!</p>
<p>Mathematically, if we have a shallower network <span class="math inline">H(x)</span> that performs well, a deeper network <span class="math inline">F(x)</span> should be able to learn an identity mapping in its additional layers, effectively becoming:</p>
<p><span class="math inline">F(x) = H(x) + (F(x) - H(x))</span></p>
<p>where <span class="math inline">(F(x) - H(x))</span> is the residual mapping. Instead of hoping that <span class="math inline">F(x)</span> will learn the entire desired mapping, we can explicitly let it learn the residual mapping <span class="math inline">(F(x) - H(x))</span>. This is the key idea behind ResNets: learning residual functions with reference to the layer inputs, rather than learning unreferenced functions.</p>
<p>This approach allows for the creation of very deep networks without the problem of vanishing gradients, as the gradient can flow directly through the skip connections (also known as shortcut connections) during backpropagation. We can imagine this as a graident highway that goes right through the network and then comes back to the input.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="resnet-architecture.png" class="img-fluid figure-img"></p>
<figcaption>This is a resnet-architecture</figcaption>
</figure>
</div>
</section>
<section id="vggs" class="level1">
<h1>VGGs</h1>
<p>Since so much of the comparison is done with VGGs it is important to understand them too. Ignoring batch dimension for now, passing through CNNs can be visualized as volumes of data moving through through the network, volume being <span class="math inline">(H, W, C)</span> where <span class="math inline">H, W</span> are the height and width of the image and <span class="math inline">C</span> is the number of channels.</p>
<div id="fig-vgg" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-vgg-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="vgg.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-vgg-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: vgg-19-architecture
</figcaption>
</figure>
</div>
<p>In VGGs</p>
<ul>
<li>there are 5 Conv blocks followed by some FC layers for classification. The Conv blocks can be thought of as a feature extractor.</li>
<li>each Conv block is a sequence of come <code>CONV-&gt;RELU</code> layers followed by a max_pool layer.</li>
<li>each conv layer has a kernel size of 3x3, stride=1 and padding=1.</li>
<li>The output of the last conv block is flattened and passed to the FC layers.</li>
<li>the FC layers have fixed sizes = [4096, 4096, 1000] with ReLU and Dropout after each layer.</li>
<li>Output is a 1000 sized vector., which represents Imagenet classes.</li>
</ul>
<section id="convrelu-layer" class="level2">
<h2 class="anchored" data-anchor-id="convrelu-layer">ConvReLU Layer</h2>
<p>Each block contains some conv_layers followed by a max_pool layer. If the input to a block is <span class="math inline">(H, W, C)</span>, the output of the block is <span class="math inline">(H/2, W/2, C*2)</span>. All in all each block still preserves the total volume.</p>
<p>Let us look inside a conv block, for eg the conv2 block in <a href="#fig-vgg" class="quarto-xref">Figure&nbsp;1</a>. We can see that the particular block has a max_pool (red) layer and 2 single-conv layers(blue). Each single-conv layer within that block is a:</p>
<p><code>conv_layer = [CNN-&gt;ReLU]</code></p>
<p>In torch,</p>
<div id="cell-3" class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch </span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> nn</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ConvReLU(nn.Module):</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co">    A single conv layer followed by batchnorm and activation.</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, in_channels, out_channels, kernel_size, activation<span class="op">=</span>nn.ReLU(), stride<span class="op">=</span><span class="dv">1</span>, padding<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv <span class="op">=</span> nn.Conv2d(in_channels, out_channels, kernel_size<span class="op">=</span>kernel_size, stride<span class="op">=</span>stride, padding<span class="op">=</span>padding)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.activation <span class="op">=</span> activation</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.activation <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> <span class="va">self</span>.activation(<span class="va">self</span>.conv(x))</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> <span class="va">self</span>.conv(x)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Lets create the conv1 layer and visualize the input and output volumes. The input is a rgb image of size <code>224x224x3</code></p>
<div id="cell-5" class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>input_img <span class="op">=</span> torch.rand(<span class="dv">224</span>, <span class="dv">224</span>, <span class="dv">3</span>)   </span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># input images must have shape (C,H,W) this is usually managed by torch's to_tensor transform</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>input_img <span class="op">=</span> torch.permute(input_img, (<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>))      </span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co"># conv layer params -&gt; C_in=3, C_out=64, K=3, S=1, P=1</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>conv_layer_1 <span class="op">=</span> ConvReLU(<span class="dv">3</span>, <span class="dv">64</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, stride<span class="op">=</span><span class="dv">1</span>, padding<span class="op">=</span><span class="dv">1</span>) </span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>conv_layer_2 <span class="op">=</span> ConvReLU(<span class="dv">64</span>, <span class="dv">64</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, stride<span class="op">=</span><span class="dv">1</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co"># max pool layer params -&gt; K=2, S=2</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>max_pool <span class="op">=</span> nn.MaxPool2d(kernel_size<span class="op">=</span><span class="dv">2</span>, stride<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"input volume = </span><span class="sc">{}</span><span class="ch">\n</span><span class="st">"</span>.<span class="bu">format</span>(input_img.shape))</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"output volume after conv_layer_1 = </span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(conv_layer_1(input_img).shape))</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"output volume after conv_layer_2 = </span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(conv_layer_2(conv_layer_1(input_img)).shape))</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="co"># print("output volume after max_pool = {}".format(max_pool(conv_layer_2(conv_layer_1(input_img))).shape))</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="block-of-convrelu-layers" class="level2">
<h2 class="anchored" data-anchor-id="block-of-convrelu-layers">Block of ConvReLU layers</h2>
<p>Now to make a block of VGG, we combine multiple such layers together. If you see the <a href="#fig-vgg" class="quarto-xref">Figure&nbsp;1</a>, each block’s has a red layer in the beginning. The red layer is a max_pool layer with stride=2 and kernel_size=2. This results in the <span class="math inline">H,W</span> being halved. Then the subsequent conv_layers preserve the <span class="math inline">H,W</span> and double the channels. Lets look at a block below:</p>
<p><code>Block = [conv_layer_1-&gt;[conv_layer_i]*(n-1)]</code>.</p>
<p>The feature extractor will look like this:</p>
<p>[<code>block_1 -&gt; Max_pool -&gt; block_2 -&gt; Max_pool -&gt; block_3 -&gt; ...</code>]</p>
<p>Lets create a block class:</p>
<div id="cell-7" class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Block(nn.Module):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_channels, num_layers, out_channels, activation<span class="op">=</span>nn.ReLU()):</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.out_channels <span class="op">=</span> input_channels<span class="op">*</span><span class="dv">2</span> <span class="cf">if</span> out_channels <span class="kw">is</span> <span class="va">None</span> <span class="cf">else</span> out_channels</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># first layer must half the H_in,W_in and double the C_in with S=2, P=1</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>        conv_1 <span class="op">=</span> ConvReLU(input_channels, <span class="va">self</span>.out_channels, kernel_size<span class="op">=</span><span class="dv">3</span>, stride<span class="op">=</span><span class="dv">1</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>        layers <span class="op">=</span> [conv_1]</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># rest of the layers preserve the H_in, W_in and C_in with S=1 and P=1</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(num_layers<span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>            conv_ <span class="op">=</span> ConvReLU(<span class="va">self</span>.out_channels, <span class="va">self</span>.out_channels, kernel_size<span class="op">=</span><span class="dv">3</span>, stride<span class="op">=</span><span class="dv">1</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>            layers.append(conv_)</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layers <span class="op">=</span> nn.Sequential(<span class="op">*</span>layers)</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.layers(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-8" class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>max_pool <span class="op">=</span> nn.MaxPool2d(kernel_size<span class="op">=</span><span class="dv">2</span>, stride<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>conv1_block <span class="op">=</span> Block(input_channels<span class="op">=</span><span class="dv">3</span>, num_layers<span class="op">=</span><span class="dv">2</span>, out_channels<span class="op">=</span><span class="dv">64</span>)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> conv1_block(input_img)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"output volume after conv1_block = </span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(x.shape))</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co"># conv_block_2 has half the h,w (due to max pool right before it) and double the input channels. </span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>conv2_block <span class="op">=</span> Block(input_channels<span class="op">=</span><span class="dv">64</span>, num_layers<span class="op">=</span><span class="dv">2</span>, out_channels<span class="op">=</span><span class="dv">128</span>)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> conv2_block(max_pool(x))</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"output volume after conv2_block = </span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(x.shape))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="vgg-model" class="level2">
<h2 class="anchored" data-anchor-id="vgg-model">VGG model</h2>
<p>We can go on this way for the rest of the blocks, but lets bring it together in a VGG class itself.</p>
<p>Lets write down the vgg configuration as a list of items. The model can be imagined as a feature extractor with a classifier head on top.</p>
<p>The classifier part has fixed configuration, but the feature extractor can be configured by passing a list of numbers and strings to the constructor. Each item is either a number or a string and represents a conv layer or a max_pool layer. The number is the number of conv layers in the block, and the string is ‘M’ which indicates a max pool layer.</p>
<p>The classifier part consists of 2 hidden-FC layers (4096 neurons each) with activations and dropout regularization added. The final layer is the classifier head with 1000 outputs. (Imagenet dataset has 1k classes)</p>
<p>Lastly, to enable the model to initialize with variable input sizes, we have used a dynamic input size of the 1st FC layer., and a dynamic hidden_fc_size for the last FC layer. This will allow us to experiment with smaller datasets locally</p>
<div id="cell-10" class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>_vgg_config <span class="op">=</span> {</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">'vgg19'</span>: [<span class="dv">64</span>, <span class="dv">64</span>, <span class="st">'M'</span>, <span class="dv">128</span>, <span class="dv">128</span>, <span class="st">'M'</span>, <span class="dv">256</span>, <span class="dv">256</span>, <span class="dv">256</span>, <span class="dv">256</span>, <span class="st">'M'</span>, <span class="dv">512</span>, <span class="dv">512</span>, <span class="dv">512</span>, <span class="dv">512</span>, <span class="st">'M'</span>, <span class="dv">512</span>, <span class="dv">512</span>, <span class="dv">512</span>, <span class="dv">512</span>, <span class="st">'M'</span>],</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'vgg11'</span>: [<span class="dv">64</span>, <span class="st">'M'</span>, <span class="dv">128</span>, <span class="st">'M'</span>, <span class="dv">256</span>, <span class="dv">256</span>, <span class="st">'M'</span>, <span class="dv">512</span>, <span class="dv">512</span>, <span class="st">'M'</span>, <span class="dv">512</span>, <span class="dv">512</span>, <span class="st">'M'</span>],</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'vgg13'</span>: [<span class="dv">64</span>, <span class="dv">64</span>, <span class="st">'M'</span>, <span class="dv">128</span>, <span class="dv">128</span>, <span class="st">'M'</span>, <span class="dv">256</span>, <span class="dv">256</span>, <span class="st">'M'</span>, <span class="dv">512</span>, <span class="dv">512</span>, <span class="st">'M'</span>, <span class="dv">512</span>, <span class="dv">512</span>, <span class="st">'M'</span>],</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'vgg16'</span>: [<span class="dv">64</span>, <span class="dv">64</span>, <span class="st">'M'</span>, <span class="dv">128</span>, <span class="dv">128</span>, <span class="st">'M'</span>, <span class="dv">256</span>, <span class="dv">256</span>, <span class="dv">256</span>, <span class="st">'M'</span>, <span class="dv">512</span>, <span class="dv">512</span>, <span class="dv">512</span>, <span class="st">'M'</span>, <span class="dv">512</span>, <span class="dv">512</span>, <span class="dv">512</span>, <span class="st">'M'</span>]</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> logging </span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>logging.basicConfig(level<span class="op">=</span>logging.DEBUG)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> VGG(nn.Module):</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, config, input_shape<span class="op">=</span>(<span class="dv">224</span>,<span class="dv">224</span>,<span class="dv">3</span>), dropout<span class="op">=</span><span class="fl">0.5</span>, num_classes<span class="op">=</span><span class="dv">1000</span>, hidden_fc_size<span class="op">=</span><span class="dv">4096</span>):</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.input_shape <span class="op">=</span> input_shape</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.output_shape <span class="op">=</span> <span class="va">self</span>.input_shape</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.hidden_fc_size <span class="op">=</span> hidden_fc_size</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>        prev_channels <span class="op">=</span> <span class="va">self</span>.input_shape[<span class="dv">2</span>]</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.blocks <span class="op">=</span> []</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> config:</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> i <span class="op">==</span> <span class="st">'M'</span>:</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.blocks.append(nn.MaxPool2d(kernel_size<span class="op">=</span><span class="dv">2</span>, stride<span class="op">=</span><span class="dv">2</span>)) </span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.output_shape <span class="op">=</span> (<span class="va">self</span>.output_shape[<span class="dv">0</span>]<span class="op">//</span><span class="dv">2</span>, <span class="va">self</span>.output_shape[<span class="dv">1</span>]<span class="op">//</span><span class="dv">2</span>, <span class="va">self</span>.output_shape[<span class="dv">2</span>])</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.blocks.append(ConvReLU(prev_channels, i, kernel_size<span class="op">=</span><span class="dv">3</span>, stride<span class="op">=</span><span class="dv">1</span>, padding<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.output_shape <span class="op">=</span> (<span class="va">self</span>.output_shape[<span class="dv">0</span>], <span class="va">self</span>.output_shape[<span class="dv">1</span>], i)</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>                prev_channels <span class="op">=</span> i</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.feature_extractor <span class="op">=</span> nn.Sequential(<span class="op">*</span><span class="va">self</span>.blocks)</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ConvMLP <span class="op">=</span> nn.Sequential(</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>            nn.Flatten(),</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.output_shape[<span class="dv">0</span>]<span class="op">*</span><span class="va">self</span>.output_shape[<span class="dv">1</span>]<span class="op">*</span><span class="va">self</span>.output_shape[<span class="dv">2</span>], <span class="va">self</span>.hidden_fc_size),</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(dropout),</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.hidden_fc_size, <span class="va">self</span>.hidden_fc_size),</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(dropout),</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.head <span class="op">=</span> nn.Linear(<span class="va">self</span>.hidden_fc_size, num_classes)</span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>        <span class="co"># if a single item turn into a batch</span></span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> x.ndim <span class="op">==</span> <span class="dv">3</span>:</span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> x.unsqueeze(<span class="dv">0</span>)</span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.feature_extractor(x)</span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x.view(x.size(<span class="dv">0</span>), <span class="op">-</span><span class="dv">1</span>)  <span class="co"># this flattens the tensor to (batch_size, -1)</span></span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.ConvMLP(x)</span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.head(x)</span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now lets visualize the model, output shapes of various layers and its size, etc using torchinfo.summary(). To install the package run <code>pip install torchinfo</code> on your terminal.</p>
<div id="cell-12" class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchinfo <span class="im">import</span> summary</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>vgg19 <span class="op">=</span> VGG(_vgg_config[<span class="st">'vgg19'</span>])</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>summary(vgg19, input_size<span class="op">=</span>(<span class="dv">3</span>,<span class="dv">224</span>,<span class="dv">224</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>A pretty huge model (140million parameters) isn’t it?! The original model was trained on the entire Imagenet dataset (150gb). But we’ll use the TinyImagenet dataset(&lt;1gb) for this example. So we’ll use a much smaller model.</p>
<div id="cell-14" class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>NUM_CLASSES<span class="op">=</span><span class="dv">200</span> <span class="co"># Tiny ImageNet has 200 classes</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>IMG_SIZE <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> <span class="st">"mps"</span> <span class="cf">if</span> torch.backends.mps.is_available() <span class="cf">else</span> <span class="st">"cpu"</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> VGG(</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    _vgg_config[<span class="st">'vgg11'</span>], </span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    input_shape<span class="op">=</span>(IMG_SIZE, IMG_SIZE, <span class="dv">3</span>), </span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    num_classes<span class="op">=</span>NUM_CLASSES,</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    hidden_fc_size<span class="op">=</span><span class="dv">1026</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>).to(device)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>summary(model, input_size<span class="op">=</span>(<span class="dv">3</span>,IMG_SIZE,IMG_SIZE))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This brings our model size down to a much more manageble 12million parameters from the original ~140 million parameters.</p>
<p>For training we’ll use the Adam optimizer and learing rate of 0.001. We’ll also use the CrossEntropyLoss as the loss function as this is a classification task.</p>
<div id="cell-16" class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader, Dataset</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> transforms</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.tensorboard <span class="im">import</span> SummaryWriter</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> urllib.request</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> zipfile</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> os.path.exists(<span class="st">"data/"</span>):</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>    os.mkdir(<span class="st">"data/"</span>)</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Hyperparameters</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>BATCH_SIZE <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>LEARNING_RATE <span class="op">=</span> <span class="fl">0.001</span></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>NUM_EPOCHS <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>DATASET_PATH <span class="op">=</span> <span class="st">"./data/tiny-imagenet-200"</span></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Download and extract Tiny ImageNet</span></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> download_and_extract_tiny_imagenet():</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>    url <span class="op">=</span> <span class="st">"http://cs231n.stanford.edu/tiny-imagenet-200.zip"</span></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>    filename <span class="op">=</span> <span class="st">"tiny-imagenet-200.zip"</span></span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>    extract_path <span class="op">=</span> DATASET_PATH</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> os.path.exists(extract_path):</span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Downloading Tiny ImageNet..."</span>)</span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>        urllib.request.urlretrieve(url, filename)</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Extracting Tiny ImageNet..."</span>)</span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> zipfile.ZipFile(filename, <span class="st">'r'</span>) <span class="im">as</span> zip_ref:</span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>            zip_ref.extractall(<span class="st">"."</span>)</span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a>        os.remove(filename)</span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Tiny ImageNet downloaded and extracted."</span>)</span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Tiny ImageNet already exists."</span>)</span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a>    os.system(<span class="st">"mv tiny-imagenet-200 data/tiny-imagenet-200"</span>)</span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> extract_path</span>
<span id="cb8-42"><a href="#cb8-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-43"><a href="#cb8-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Custom Dataset for Tiny ImageNet</span></span>
<span id="cb8-44"><a href="#cb8-44" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TinyImageNetDataset(Dataset):</span>
<span id="cb8-45"><a href="#cb8-45" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, root, split<span class="op">=</span><span class="st">'train'</span>, transform<span class="op">=</span><span class="va">None</span>, labels<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb8-46"><a href="#cb8-46" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.root <span class="op">=</span> root</span>
<span id="cb8-47"><a href="#cb8-47" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.split <span class="op">=</span> split</span>
<span id="cb8-48"><a href="#cb8-48" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.transform <span class="op">=</span> transform</span>
<span id="cb8-49"><a href="#cb8-49" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.images <span class="op">=</span> []</span>
<span id="cb8-50"><a href="#cb8-50" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.labels <span class="op">=</span> []</span>
<span id="cb8-51"><a href="#cb8-51" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb8-52"><a href="#cb8-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-53"><a href="#cb8-53" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> split <span class="op">==</span> <span class="st">'train'</span>:</span>
<span id="cb8-54"><a href="#cb8-54" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> class_dir <span class="kw">in</span> os.listdir(os.path.join(root, <span class="st">'train'</span>)):</span>
<span id="cb8-55"><a href="#cb8-55" aria-hidden="true" tabindex="-1"></a>                class_path <span class="op">=</span> os.path.join(root, <span class="st">'train'</span>, class_dir, <span class="st">'images'</span>)</span>
<span id="cb8-56"><a href="#cb8-56" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> img_name <span class="kw">in</span> os.listdir(class_path):</span>
<span id="cb8-57"><a href="#cb8-57" aria-hidden="true" tabindex="-1"></a>                    <span class="va">self</span>.images.append(os.path.join(class_path, img_name))</span>
<span id="cb8-58"><a href="#cb8-58" aria-hidden="true" tabindex="-1"></a>                    <span class="va">self</span>.labels.append(<span class="bu">int</span>(class_dir[<span class="dv">1</span>:]))</span>
<span id="cb8-59"><a href="#cb8-59" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> split <span class="op">==</span> <span class="st">'val'</span>:</span>
<span id="cb8-60"><a href="#cb8-60" aria-hidden="true" tabindex="-1"></a>            val_annotations <span class="op">=</span> os.path.join(root, <span class="st">'val'</span>, <span class="st">'val_annotations.txt'</span>)</span>
<span id="cb8-61"><a href="#cb8-61" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> <span class="bu">open</span>(val_annotations, <span class="st">'r'</span>) <span class="im">as</span> f:</span>
<span id="cb8-62"><a href="#cb8-62" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> line <span class="kw">in</span> f:</span>
<span id="cb8-63"><a href="#cb8-63" aria-hidden="true" tabindex="-1"></a>                    img_name, class_id, _, _, _, _ <span class="op">=</span> line.strip().split(<span class="st">'</span><span class="ch">\t</span><span class="st">'</span>)</span>
<span id="cb8-64"><a href="#cb8-64" aria-hidden="true" tabindex="-1"></a>                    <span class="bu">print</span>()</span>
<span id="cb8-65"><a href="#cb8-65" aria-hidden="true" tabindex="-1"></a>                    <span class="va">self</span>.images.append(os.path.join(root, <span class="st">'val'</span>, <span class="st">'images'</span>, img_name))</span>
<span id="cb8-66"><a href="#cb8-66" aria-hidden="true" tabindex="-1"></a>                    <span class="va">self</span>.labels.append(<span class="bu">int</span>(class_id[<span class="dv">1</span>:]))</span>
<span id="cb8-67"><a href="#cb8-67" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.labelset <span class="op">=</span> <span class="bu">list</span>(<span class="bu">set</span>(<span class="va">self</span>.labels)) <span class="cf">if</span> labels <span class="kw">is</span> <span class="va">None</span> <span class="cf">else</span> labels</span>
<span id="cb8-68"><a href="#cb8-68" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.labels_to_class <span class="op">=</span> {label:idx <span class="cf">for</span> idx,label <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="va">self</span>.labelset)}</span>
<span id="cb8-69"><a href="#cb8-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-70"><a href="#cb8-70" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb8-71"><a href="#cb8-71" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.images)</span>
<span id="cb8-72"><a href="#cb8-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-73"><a href="#cb8-73" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, idx):</span>
<span id="cb8-74"><a href="#cb8-74" aria-hidden="true" tabindex="-1"></a>        img_path <span class="op">=</span> <span class="va">self</span>.images[idx]</span>
<span id="cb8-75"><a href="#cb8-75" aria-hidden="true" tabindex="-1"></a>        label <span class="op">=</span> <span class="va">self</span>.labels_to_class[<span class="va">self</span>.labels[idx]]</span>
<span id="cb8-76"><a href="#cb8-76" aria-hidden="true" tabindex="-1"></a>        image <span class="op">=</span> Image.<span class="bu">open</span>(img_path).convert(<span class="st">'RGB'</span>)</span>
<span id="cb8-77"><a href="#cb8-77" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb8-78"><a href="#cb8-78" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.transform:</span>
<span id="cb8-79"><a href="#cb8-79" aria-hidden="true" tabindex="-1"></a>            image <span class="op">=</span> <span class="va">self</span>.transform(image)</span>
<span id="cb8-80"><a href="#cb8-80" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb8-81"><a href="#cb8-81" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> image, label</span>
<span id="cb8-82"><a href="#cb8-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-83"><a href="#cb8-83" aria-hidden="true" tabindex="-1"></a><span class="co"># Download and extract the dataset</span></span>
<span id="cb8-84"><a href="#cb8-84" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> os.path.exists(<span class="st">"./data/tiny-imagenet-200"</span>):</span>
<span id="cb8-85"><a href="#cb8-85" aria-hidden="true" tabindex="-1"></a>    dataset_path <span class="op">=</span> DATASET_PATH</span>
<span id="cb8-86"><a href="#cb8-86" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb8-87"><a href="#cb8-87" aria-hidden="true" tabindex="-1"></a>    dataset_path <span class="op">=</span> download_and_extract_tiny_imagenet()</span>
<span id="cb8-88"><a href="#cb8-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-89"><a href="#cb8-89" aria-hidden="true" tabindex="-1"></a><span class="co"># Data transforms</span></span>
<span id="cb8-90"><a href="#cb8-90" aria-hidden="true" tabindex="-1"></a>train_transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb8-91"><a href="#cb8-91" aria-hidden="true" tabindex="-1"></a>    <span class="co"># transforms.RandomResizedCrop(64),</span></span>
<span id="cb8-92"><a href="#cb8-92" aria-hidden="true" tabindex="-1"></a>    transforms.RandomHorizontalFlip(),</span>
<span id="cb8-93"><a href="#cb8-93" aria-hidden="true" tabindex="-1"></a>    transforms.ColorJitter(brightness<span class="op">=</span><span class="fl">0.2</span>, contrast<span class="op">=</span><span class="fl">0.2</span>, saturation<span class="op">=</span><span class="fl">0.2</span>, hue<span class="op">=</span><span class="fl">0.1</span>),</span>
<span id="cb8-94"><a href="#cb8-94" aria-hidden="true" tabindex="-1"></a>    transforms.ToTensor(),</span>
<span id="cb8-95"><a href="#cb8-95" aria-hidden="true" tabindex="-1"></a>    transforms.Normalize(mean<span class="op">=</span>[<span class="fl">0.485</span>, <span class="fl">0.456</span>, <span class="fl">0.406</span>], std<span class="op">=</span>[<span class="fl">0.229</span>, <span class="fl">0.224</span>, <span class="fl">0.225</span>])</span>
<span id="cb8-96"><a href="#cb8-96" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb8-97"><a href="#cb8-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-98"><a href="#cb8-98" aria-hidden="true" tabindex="-1"></a>val_transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb8-99"><a href="#cb8-99" aria-hidden="true" tabindex="-1"></a>    <span class="co"># transforms.Resize(64),</span></span>
<span id="cb8-100"><a href="#cb8-100" aria-hidden="true" tabindex="-1"></a>    <span class="co"># transforms.CenterCrop(64),</span></span>
<span id="cb8-101"><a href="#cb8-101" aria-hidden="true" tabindex="-1"></a>    transforms.ToTensor(),</span>
<span id="cb8-102"><a href="#cb8-102" aria-hidden="true" tabindex="-1"></a>    transforms.Normalize(mean<span class="op">=</span>[<span class="fl">0.485</span>, <span class="fl">0.456</span>, <span class="fl">0.406</span>], std<span class="op">=</span>[<span class="fl">0.229</span>, <span class="fl">0.224</span>, <span class="fl">0.225</span>])</span>
<span id="cb8-103"><a href="#cb8-103" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb8-104"><a href="#cb8-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-105"><a href="#cb8-105" aria-hidden="true" tabindex="-1"></a><span class="co"># Load datasets</span></span>
<span id="cb8-106"><a href="#cb8-106" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> TinyImageNetDataset(dataset_path, split<span class="op">=</span><span class="st">'train'</span>, transform<span class="op">=</span>train_transform)</span>
<span id="cb8-107"><a href="#cb8-107" aria-hidden="true" tabindex="-1"></a>val_dataset <span class="op">=</span> TinyImageNetDataset(dataset_path, split<span class="op">=</span><span class="st">'val'</span>, transform<span class="op">=</span>val_transform, labels<span class="op">=</span>train_dataset.labelset)</span>
<span id="cb8-108"><a href="#cb8-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-109"><a href="#cb8-109" aria-hidden="true" tabindex="-1"></a><span class="co"># Create data loaders</span></span>
<span id="cb8-110"><a href="#cb8-110" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> DataLoader(train_dataset, batch_size<span class="op">=</span>BATCH_SIZE, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb8-111"><a href="#cb8-111" aria-hidden="true" tabindex="-1"></a>val_loader <span class="op">=</span> DataLoader(val_dataset, batch_size<span class="op">=</span>BATCH_SIZE, shuffle<span class="op">=</span><span class="va">False</span>, num_workers<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb8-112"><a href="#cb8-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-113"><a href="#cb8-113" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize model, loss function, and optimizer</span></span>
<span id="cb8-114"><a href="#cb8-114" aria-hidden="true" tabindex="-1"></a>criterion <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb8-115"><a href="#cb8-115" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> optim.Adam(model.parameters(), lr<span class="op">=</span>LEARNING_RATE)</span>
<span id="cb8-116"><a href="#cb8-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-117"><a href="#cb8-117" aria-hidden="true" tabindex="-1"></a><span class="co"># TensorBoard writer</span></span>
<span id="cb8-118"><a href="#cb8-118" aria-hidden="true" tabindex="-1"></a>writer <span class="op">=</span> SummaryWriter(<span class="st">'runs/vgg_tiny_imagenet'</span>)</span>
<span id="cb8-119"><a href="#cb8-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-120"><a href="#cb8-120" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_and_validate(epoch):</span>
<span id="cb8-121"><a href="#cb8-121" aria-hidden="true" tabindex="-1"></a>    model.train()</span>
<span id="cb8-122"><a href="#cb8-122" aria-hidden="true" tabindex="-1"></a>    train_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-123"><a href="#cb8-123" aria-hidden="true" tabindex="-1"></a>    train_correct <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-124"><a href="#cb8-124" aria-hidden="true" tabindex="-1"></a>    val_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-125"><a href="#cb8-125" aria-hidden="true" tabindex="-1"></a>    val_correct <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-126"><a href="#cb8-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-127"><a href="#cb8-127" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Training</span></span>
<span id="cb8-128"><a href="#cb8-128" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch_idx, (data, target) <span class="kw">in</span> <span class="bu">enumerate</span>(tqdm(train_loader, desc<span class="op">=</span><span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>NUM_EPOCHS<span class="sc">}</span><span class="ss"> - Training"</span>)):</span>
<span id="cb8-129"><a href="#cb8-129" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(batch_idx)</span>
<span id="cb8-130"><a href="#cb8-130" aria-hidden="true" tabindex="-1"></a>        data, target <span class="op">=</span> data.to(device), target.to(device)</span>
<span id="cb8-131"><a href="#cb8-131" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb8-132"><a href="#cb8-132" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> model(data)</span>
<span id="cb8-133"><a href="#cb8-133" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> criterion(output, target)</span>
<span id="cb8-134"><a href="#cb8-134" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb8-135"><a href="#cb8-135" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb8-136"><a href="#cb8-136" aria-hidden="true" tabindex="-1"></a>        train_loss <span class="op">+=</span> loss.item()</span>
<span id="cb8-137"><a href="#cb8-137" aria-hidden="true" tabindex="-1"></a>        pred <span class="op">=</span> output.argmax(dim<span class="op">=</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-138"><a href="#cb8-138" aria-hidden="true" tabindex="-1"></a>        train_correct <span class="op">+=</span> pred.eq(target.view_as(pred)).<span class="bu">sum</span>().item()</span>
<span id="cb8-139"><a href="#cb8-139" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"train loss </span><span class="sc">{</span>torch<span class="sc">.</span>mean(train_loss)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb8-140"><a href="#cb8-140" aria-hidden="true" tabindex="-1"></a>        writer.add_scalar(<span class="st">'Loss/train_step'</span>, loss.item())</span>
<span id="cb8-141"><a href="#cb8-141" aria-hidden="true" tabindex="-1"></a>        <span class="co"># writer.add_scalar('Loss/val', val_loss, epoch)</span></span>
<span id="cb8-142"><a href="#cb8-142" aria-hidden="true" tabindex="-1"></a>    train_loss <span class="op">/=</span> <span class="bu">len</span>(train_loader)</span>
<span id="cb8-143"><a href="#cb8-143" aria-hidden="true" tabindex="-1"></a>    train_accuracy <span class="op">=</span> <span class="fl">100.</span> <span class="op">*</span> train_correct <span class="op">/</span> <span class="bu">len</span>(train_loader.dataset)</span>
<span id="cb8-144"><a href="#cb8-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-145"><a href="#cb8-145" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Validation</span></span>
<span id="cb8-146"><a href="#cb8-146" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb8-147"><a href="#cb8-147" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb8-148"><a href="#cb8-148" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> data, target <span class="kw">in</span> tqdm(val_loader, desc<span class="op">=</span><span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>NUM_EPOCHS<span class="sc">}</span><span class="ss"> - Validation"</span>):</span>
<span id="cb8-149"><a href="#cb8-149" aria-hidden="true" tabindex="-1"></a>            data, target <span class="op">=</span> data.to(device), target.to(device)</span>
<span id="cb8-150"><a href="#cb8-150" aria-hidden="true" tabindex="-1"></a>            output <span class="op">=</span> model(data)</span>
<span id="cb8-151"><a href="#cb8-151" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> criterion(output, target)</span>
<span id="cb8-152"><a href="#cb8-152" aria-hidden="true" tabindex="-1"></a>            val_loss <span class="op">+=</span> loss.item()</span>
<span id="cb8-153"><a href="#cb8-153" aria-hidden="true" tabindex="-1"></a>            pred <span class="op">=</span> output.argmax(dim<span class="op">=</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-154"><a href="#cb8-154" aria-hidden="true" tabindex="-1"></a>            writer.add_scalar(<span class="st">'Loss/val_step'</span>, loss.item())</span>
<span id="cb8-155"><a href="#cb8-155" aria-hidden="true" tabindex="-1"></a>            val_correct <span class="op">+=</span> pred.eq(target.view_as(pred)).<span class="bu">sum</span>().item()</span>
<span id="cb8-156"><a href="#cb8-156" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"val loss </span><span class="sc">{</span>torch<span class="sc">.</span>mean(val_loss)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb8-157"><a href="#cb8-157" aria-hidden="true" tabindex="-1"></a>    val_loss <span class="op">/=</span> <span class="bu">len</span>(val_loader)</span>
<span id="cb8-158"><a href="#cb8-158" aria-hidden="true" tabindex="-1"></a>    val_accuracy <span class="op">=</span> <span class="fl">100.</span> <span class="op">*</span> val_correct <span class="op">/</span> <span class="bu">len</span>(val_loader.dataset)</span>
<span id="cb8-159"><a href="#cb8-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-160"><a href="#cb8-160" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Log to TensorBoard</span></span>
<span id="cb8-161"><a href="#cb8-161" aria-hidden="true" tabindex="-1"></a>    writer.add_scalar(<span class="st">'Loss/train'</span>, train_loss, epoch)</span>
<span id="cb8-162"><a href="#cb8-162" aria-hidden="true" tabindex="-1"></a>    writer.add_scalar(<span class="st">'Loss/val'</span>, val_loss, epoch)</span>
<span id="cb8-163"><a href="#cb8-163" aria-hidden="true" tabindex="-1"></a>    writer.add_scalar(<span class="st">'Accuracy/train'</span>, train_accuracy, epoch)</span>
<span id="cb8-164"><a href="#cb8-164" aria-hidden="true" tabindex="-1"></a>    writer.add_scalar(<span class="st">'Accuracy/val'</span>, val_accuracy, epoch)</span>
<span id="cb8-165"><a href="#cb8-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-166"><a href="#cb8-166" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>NUM_EPOCHS<span class="sc">}</span><span class="ss">:'</span>)</span>
<span id="cb8-167"><a href="#cb8-167" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Train Loss: </span><span class="sc">{</span>train_loss<span class="sc">:.4f}</span><span class="ss">, Train Accuracy: </span><span class="sc">{</span>train_accuracy<span class="sc">:.2f}</span><span class="ss">%'</span>)</span>
<span id="cb8-168"><a href="#cb8-168" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Val Loss: </span><span class="sc">{</span>val_loss<span class="sc">:.4f}</span><span class="ss">, Val Accuracy: </span><span class="sc">{</span>val_accuracy<span class="sc">:.2f}</span><span class="ss">%'</span>)</span>
<span id="cb8-169"><a href="#cb8-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-170"><a href="#cb8-170" aria-hidden="true" tabindex="-1"></a><span class="co"># Training loop</span></span>
<span id="cb8-171"><a href="#cb8-171" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(NUM_EPOCHS):</span>
<span id="cb8-172"><a href="#cb8-172" aria-hidden="true" tabindex="-1"></a>    train_and_validate(epoch)</span>
<span id="cb8-173"><a href="#cb8-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-174"><a href="#cb8-174" aria-hidden="true" tabindex="-1"></a>writer.close()</span>
<span id="cb8-175"><a href="#cb8-175" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Training completed!"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>Running vgg11 on colab gives us a score of ~28% accuracy on the validation set in 20 epochs, while training loss and val loss both were kind of still decreasing.</li>
</ul>
<div id="cell-18" class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_params_and_grads(model, n<span class="op">=</span><span class="dv">3</span>):</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    grad_values <span class="op">=</span> [(name, param.grad.<span class="bu">abs</span>().cpu().detach().numpy())</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>                   <span class="cf">for</span> name, param <span class="kw">in</span> model.named_parameters()</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>                   <span class="cf">if</span> param.grad <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>]</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> plot_grads(grad_values, title_prefix):</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>        num_plots <span class="op">=</span> <span class="bu">min</span>(n, <span class="bu">len</span>(grad_values))</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>        fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, num_plots, figsize<span class="op">=</span>(<span class="dv">5</span> <span class="op">*</span> num_plots, <span class="dv">5</span>))</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> num_plots <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>            axes <span class="op">=</span> [axes]  <span class="co"># Ensure axes is iterable if only one plot</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> idx <span class="kw">in</span> <span class="bu">range</span>(num_plots):</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>            name, grad <span class="op">=</span> grad_values[idx]</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>            axes[idx].hist(grad.flatten(), bins<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>            axes[idx].set_title(<span class="ss">f'</span><span class="sc">{</span>title_prefix<span class="sc">}</span><span class="ss"> Layer </span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>            axes[idx].set_xlabel(<span class="st">'Gradient Magnitude'</span>)</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>            axes[idx].set_ylabel(<span class="st">'Frequency'</span>)</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>        plt.tight_layout()</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>        plt.show()</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot first n parameters</span></span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>    plot_grads(grad_values[:n], title_prefix<span class="op">=</span><span class="st">'First'</span>)</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot last n parameters</span></span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>    plot_grads(grad_values[<span class="op">-</span>n:], title_prefix<span class="op">=</span><span class="st">'Last'</span>)</span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a>plot_params_and_grads(model, n<span class="op">=</span><span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li><p>Scaling to vgg_16:</p>
<pre><code>  suprisingly model isnt learning at all. loss not going down. upon inspection of gradients we find that while training vgg_199 there are practically no gradients.

  Also note that grads start even when loss isnt decreasing at the first few steps.</code></pre>
<p>Look at the the below figures:</p>
<p>### VGG-11 <img src="./vgg_11_final_layer_grads.png" id="fig-vgg_11_final_layer_grads" style="width:100.0%" alt="‘VGG-11 Final Layer Gradients’"></p>
<div id="fig-vgg_11_first_layers_grad_plot" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-vgg_11_first_layers_grad_plot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./vgg_11_first_layers_grad_plot.png" style="width:100.0%" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-vgg_11_first_layers_grad_plot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: “VGG-11 First Layers Gradient Plot”
</figcaption>
</figure>
</div>
<p>### VGG-16 <img src="./vgg_16_final_layers_grad.png" id="fig-vgg_16_final_layers_grad" style="width:100.0%" alt="“VGG-16 Final Layers Gradients”"></p>
<div id="fig-vgg_16_first_layers_grad_plot_vanishing-grads" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-vgg_16_first_layers_grad_plot_vanishing-grads-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./vgg_16_first_layers_grad_plot_vanishing-grads.png" style="width:100.0%" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-vgg_16_first_layers_grad_plot_vanishing-grads-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: “VGG-16 First Layers Gradient Plot”(Vanishing Gradients)
</figcaption>
</figure>
</div></li>
<li><p>Does removing bottlenecked maxpool before fc layers help?: No, it doesnt. :(</p></li>
<li><p>what about vgg13? being clser to the 11 variant this doesnt experience vanishing gradients.</p></li>
</ul>
<p>This is esssentialy the central limitations that still remain after going very deep. Depth is not enough, we need better ways to allow gradients to be propagated through these deep networks.</p>
<section id="computational-considerations" class="level3">
<h3 class="anchored" data-anchor-id="computational-considerations">computational considerations</h3>
<p>A usual Conv2d layer has a computation complexity of <span class="math inline">O(H_{in}*W_{in}*k^2*C_{in}*C_{out})</span>. Derivation:</p>
<ul>
<li>number of output cells = <span class="math inline">H_{out}*W_{out}*C_{out}</span></li>
<li>computation required to compute each output cell = <span class="math inline">k^2*C_{in}</span></li>
<li>number of ops<br>
-&gt; number of output cells * computation required to compute each output cell<br>
-&gt; <span class="math inline">H_{out}*W_{out}*k^2*C_{in}*C_{out}</span></li>
</ul>
</section>
</section>
</section>
<section id="inception" class="level1">
<h1>Inception</h1>
<p>VGGs large networks deal with issues of overfitting and increased computation. After it focus shifted to making the networks more compute efficient. Aiming to solve these issues by introducing extra sparsity in the network, the Inception model was proposed.</p>
<div id="cell-22" class="cell" data-execution_count="136">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> NaiveInceptionBlock(nn.Module):</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, in_channels, out_channels):</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(NaiveInceptionBlock, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv1x1 <span class="op">=</span> nn.Conv2d(in_channels, out_channels, kernel_size<span class="op">=</span><span class="dv">1</span>, stride<span class="op">=</span><span class="dv">1</span>, padding<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv3x3 <span class="op">=</span> nn.Conv2d(in_channels, out_channels, kernel_size<span class="op">=</span><span class="dv">3</span>, stride<span class="op">=</span><span class="dv">1</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv5x5 <span class="op">=</span> nn.Conv2d(in_channels, out_channels, kernel_size<span class="op">=</span><span class="dv">5</span>, stride<span class="op">=</span><span class="dv">1</span>, padding<span class="op">=</span><span class="dv">2</span>) <span class="co"># padding to make sure h,w remains same</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.maxpool <span class="op">=</span> nn.MaxPool2d(kernel_size<span class="op">=</span><span class="dv">3</span>, stride<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>        out1 <span class="op">=</span> <span class="va">self</span>.conv1x1(x)</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>        out2 <span class="op">=</span> <span class="va">self</span>.conv3x3(x)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>        out3 <span class="op">=</span> <span class="va">self</span>.conv5x5(x)</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># out4 = self.maxpool(x)</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.cat([out1, out2, out3], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># return [out1, out2, out3, out4]</span></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> InceptionBlock(nn.Module):</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, in_channels, out_channels_1, out_channels_3, out_channels_5, out_channels_dim_red_3, out_channels_dim_red_5, pool_proj_dim):</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(InceptionBlock, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv1x1 <span class="op">=</span> ConvReLU(in_channels, out_channels_1, kernel_size<span class="op">=</span><span class="dv">1</span>, stride<span class="op">=</span><span class="dv">1</span>, padding<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dim_reduction_3x3 <span class="op">=</span> ConvReLU(in_channels, out_channels_dim_red_3, kernel_size<span class="op">=</span><span class="dv">1</span>, stride<span class="op">=</span><span class="dv">1</span>, padding<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv3x3 <span class="op">=</span> ConvReLU(out_channels_dim_red_3, out_channels_3, kernel_size<span class="op">=</span><span class="dv">3</span>, stride<span class="op">=</span><span class="dv">1</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dim_reduction_5x5 <span class="op">=</span> ConvReLU(in_channels, out_channels_dim_red_5, kernel_size<span class="op">=</span><span class="dv">1</span>, stride<span class="op">=</span><span class="dv">1</span>, padding<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv5x5 <span class="op">=</span> ConvReLU(out_channels_dim_red_5, out_channels_5, kernel_size<span class="op">=</span><span class="dv">5</span>, stride<span class="op">=</span><span class="dv">1</span>, padding<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.maxpool <span class="op">=</span> nn.MaxPool2d(kernel_size<span class="op">=</span><span class="dv">3</span>, stride<span class="op">=</span><span class="dv">1</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pool_proj <span class="op">=</span> ConvReLU(in_channels, pool_proj_dim, kernel_size<span class="op">=</span><span class="dv">1</span>, stride<span class="op">=</span><span class="dv">1</span>, padding<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a>        out1 <span class="op">=</span> <span class="va">self</span>.conv1x1(x)</span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a>        out2 <span class="op">=</span> <span class="va">self</span>.dim_reduction_3x3(x)</span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a>        out2 <span class="op">=</span> <span class="va">self</span>.conv3x3(out2)</span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a>        out3 <span class="op">=</span> <span class="va">self</span>.dim_reduction_5x5(x)</span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a>        out3 <span class="op">=</span> <span class="va">self</span>.conv5x5(out3)</span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-42"><a href="#cb11-42" aria-hidden="true" tabindex="-1"></a>        out4 <span class="op">=</span> <span class="va">self</span>.maxpool(x)</span>
<span id="cb11-43"><a href="#cb11-43" aria-hidden="true" tabindex="-1"></a>        out4 <span class="op">=</span> <span class="va">self</span>.pool_proj(out4)</span>
<span id="cb11-44"><a href="#cb11-44" aria-hidden="true" tabindex="-1"></a>        <span class="co"># return [out1, out2, out3, out4]</span></span>
<span id="cb11-45"><a href="#cb11-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.cat([out1, out2, out3, out4], dim<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-23" class="cell" data-execution_count="140">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>inp <span class="op">=</span> torch.rand(<span class="dv">1</span>, <span class="dv">256</span>, <span class="dv">64</span>, <span class="dv">64</span>) <span class="co"># some intermediate layer output</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>block <span class="op">=</span> NaiveInceptionBlock(<span class="dv">256</span>, <span class="dv">64</span>)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>out <span class="op">=</span> block(inp)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(out.shape)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(summary(NaiveInceptionBlock(<span class="dv">256</span>, <span class="dv">64</span>), input_size<span class="op">=</span>(<span class="dv">256</span>, <span class="dv">64</span>, <span class="dv">64</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([1, 192, 64, 64])
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
NaiveInceptionBlock                      [64, 192, 64]             --
├─Conv2d: 1-1                            [64, 64, 64]              16,448
├─Conv2d: 1-2                            [64, 64, 64]              147,520
├─Conv2d: 1-3                            [64, 64, 64]              409,664
==========================================================================================
Total params: 573,632
Trainable params: 573,632
Non-trainable params: 0
Total mult-adds (G): 2.35
==========================================================================================
Input size (MB): 4.19
Forward/backward pass size (MB): 6.29
Params size (MB): 2.29
Estimated Total Size (MB): 12.78
==========================================================================================</code></pre>
</div>
</div>
<div id="cell-24" class="cell" data-execution_count="129">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>conv_block <span class="op">=</span> ConvReLU(<span class="dv">256</span>, <span class="dv">192</span>, <span class="dv">3</span>)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>out <span class="op">=</span> conv_block(inp)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(out.shape)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(summary(conv_block, input_size<span class="op">=</span>(<span class="dv">256</span>, <span class="dv">64</span>, <span class="dv">64</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([1, 192, 64, 64])
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
ConvReLU                                 [192, 64, 64]             --
├─Conv2d: 1-1                            [192, 64, 64]             442,560
├─ReLU: 1-2                              [192, 64, 64]             --
==========================================================================================
Total params: 442,560
Trainable params: 442,560
Non-trainable params: 0
Total mult-adds (G): 5.44
==========================================================================================
Input size (MB): 4.19
Forward/backward pass size (MB): 6.29
Params size (MB): 1.77
Estimated Total Size (MB): 12.26
==========================================================================================</code></pre>
</div>
</div>
<div id="cell-25" class="cell" data-execution_count="147">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>out_channels <span class="op">=</span> <span class="dv">192</span><span class="op">//</span><span class="dv">4</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>block <span class="op">=</span> InceptionBlock(<span class="dv">256</span>, out_channels, out_channels, out_channels, <span class="dv">64</span>, <span class="dv">32</span>, out_channels)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>out <span class="op">=</span> block(inp)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(out.shape)</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(summary(block, input_size<span class="op">=</span>(<span class="dv">256</span>, <span class="dv">224</span>, <span class="dv">224</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([1, 192, 64, 64])
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
InceptionBlock                           [48, 896, 224]            --
├─ConvReLU: 1-1                          [48, 224, 224]            --
│    └─Conv2d: 2-1                       [48, 224, 224]            12,336
├─ConvReLU: 1-10                         --                        (recursive)
│    └─ReLU: 2-2                         [48, 224, 224]            --
├─ConvReLU: 1-3                          [64, 224, 224]            --
│    └─Conv2d: 2-3                       [64, 224, 224]            16,448
├─ConvReLU: 1-10                         --                        (recursive)
│    └─ReLU: 2-4                         [64, 224, 224]            --
├─ConvReLU: 1-5                          [48, 224, 224]            --
│    └─Conv2d: 2-5                       [48, 224, 224]            27,696
├─ConvReLU: 1-10                         --                        (recursive)
│    └─ReLU: 2-6                         [48, 224, 224]            --
├─ConvReLU: 1-7                          [32, 224, 224]            --
│    └─Conv2d: 2-7                       [32, 224, 224]            8,224
├─ConvReLU: 1-10                         --                        (recursive)
│    └─ReLU: 2-8                         [32, 224, 224]            --
├─ConvReLU: 1-9                          [48, 224, 224]            --
│    └─Conv2d: 2-9                       [48, 224, 224]            38,448
├─ConvReLU: 1-10                         --                        (recursive)
│    └─ReLU: 2-10                        [48, 224, 224]            --
├─MaxPool2d: 1-11                        [256, 224, 224]           --
├─ConvReLU: 1-12                         [48, 224, 224]            --
│    └─Conv2d: 2-11                      [48, 224, 224]            12,336
│    └─ReLU: 2-12                        [48, 224, 224]            --
==========================================================================================
Total params: 115,488
Trainable params: 115,488
Non-trainable params: 0
Total mult-adds (G): 1.27
==========================================================================================
Input size (MB): 51.38
Forward/backward pass size (MB): 115.61
Params size (MB): 0.46
Estimated Total Size (MB): 167.45
==========================================================================================</code></pre>
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/www\.deepamminda\.com");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>