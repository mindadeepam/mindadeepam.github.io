<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.53">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Deepam Minda">
<meta name="dcterms.date" content="2024-07-30">

<title>Intro to Convolution Neural Networks – deepamminda</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">deepamminda</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About Me</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../blog.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../links.html"> 
<span class="menu-text">Links</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/mindadeepam"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/mindadeepam"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Intro to Convolution Neural Networks</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">cnns</div>
                <div class="quarto-category">deep-learning</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Deepam Minda </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">July 30, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#convolutions" id="toc-convolutions" class="nav-link active" data-scroll-target="#convolutions">Convolutions</a>
  <ul class="collapse">
  <li><a href="#steps-in-convolution" id="toc-steps-in-convolution" class="nav-link" data-scroll-target="#steps-in-convolution">Steps in Convolution</a></li>
  </ul></li>
  <li><a href="#neural-networks" id="toc-neural-networks" class="nav-link" data-scroll-target="#neural-networks">Neural networks</a></li>
  <li><a href="#convolutional-layer" id="toc-convolutional-layer" class="nav-link" data-scroll-target="#convolutional-layer">Convolutional layer</a></li>
  <li><a href="#other-layers" id="toc-other-layers" class="nav-link" data-scroll-target="#other-layers">Other layers</a>
  <ul class="collapse">
  <li><a href="#pooling-layer" id="toc-pooling-layer" class="nav-link" data-scroll-target="#pooling-layer">Pooling layer</a></li>
  <li><a href="#activation-layer" id="toc-activation-layer" class="nav-link" data-scroll-target="#activation-layer">Activation layer</a></li>
  <li><a href="#other-jargon" id="toc-other-jargon" class="nav-link" data-scroll-target="#other-jargon">Other jargon</a></li>
  </ul></li>
  <li><a href="#a-simple-cnn-architecture" id="toc-a-simple-cnn-architecture" class="nav-link" data-scroll-target="#a-simple-cnn-architecture">A Simple CNN architecture</a></li>
  <li><a href="#cnn-characteristics" id="toc-cnn-characteristics" class="nav-link" data-scroll-target="#cnn-characteristics">CNN characteristics</a></li>
  <li><a href="#lets-train-a-model-yaar" id="toc-lets-train-a-model-yaar" class="nav-link" data-scroll-target="#lets-train-a-model-yaar">Lets train a model yaar</a></li>
  <li><a href="#concluding" id="toc-concluding" class="nav-link" data-scroll-target="#concluding">Concluding</a></li>
  <li><a href="#references-and-further-reading" id="toc-references-and-further-reading" class="nav-link" data-scroll-target="#references-and-further-reading">References and Further Reading</a></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="00_cnn_basics.out.ipynb" download="00_cnn_basics.out.ipynb"><i class="bi bi-journal-code"></i>Jupyter</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>Welcome to the land of vision in deep learning. Gone are the days you need to look at 10 types of thresholding and 20 types of data pre-processing and apply a logistic classifier on the outputs of a cnn feature extractor. These days you can just load a pretrained model and watch a decaying training and validation loss and feel good about yourself.</p>
<p>Turns out, this comfort doesnt last long. You eventually get around to understand what these models actually are because you need to! And when it comes to vision, you surely cannot leave out CNNs. Sure its all transformers nowadays but CNNs or convolutional neural networks were essentially the first deep learning models to make a significant impact in the field of computer vision and most would agree started the whole deep learning wave in the modern era. AlexNet, VGG, resnets would be considered the pioneer models in this field.</p>
<p>Now you might ask: All this sounds interesting Deepam, but what the hell is a convolution? Let us understand convolutions and build a simple CNN model from scratch.</p>
<p>The pre-requisites for this post are:</p>
<ul>
<li>Basic understanding of python, numpy and torch.</li>
<li>Basic understanding of neural networks and feed forward networks.</li>
</ul>
<section id="convolutions" class="level2">
<h2 class="anchored" data-anchor-id="convolutions">Convolutions</h2>
<p>Convolutions is just an operation between 2 signals (vectors/matrices/continuous-signals) that returns a 3rd signal. It represents how one signal modifies the other signal. In general terms, convolution is used to apply a filter to a signal or data. (We’ll understand convolution for discrete signals)</p>
<section id="steps-in-convolution" class="level3">
<h3 class="anchored" data-anchor-id="steps-in-convolution">Steps in Convolution</h3>
<p>Let’s consider two signals: the input signal <span class="math inline">\((f)\)</span> and the kernel/filter <span class="math inline">\((g)\)</span>.</p>
<p>Convolution involves the following steps:</p>
<ol type="1">
<li><p><strong>Prepare the Kernel</strong>: Flip the kernel <span class="math inline">\((g)\)</span> both horizontally and vertically. This step ensures the operation is commutative and maintains time-reversal properties. <a href="https://dsp.stackexchange.com/questions/5992/flipping-the-impulse-response-in-convolution/6355#6355">More details</a></p></li>
<li><p><strong>Align and Slide</strong>: Position the flipped kernel at the start of the input signal <span class="math inline">\((f)\)</span>. Then, systematically slide it across the entire length of <span class="math inline">\((f)\)</span>.</p></li>
<li><p><strong>Multiply</strong>: At each position, perform element-wise multiplication between the overlapping portions of the flipped kernel and the input signal.</p></li>
<li><p><strong>Sum</strong>: Add up all the products from step 3 to get a single value. This value represents the convolution result at the current position.</p></li>
<li><p><strong>Record and Repeat</strong>: Store the sum as an element in the output signal, then move the kernel to the next position and repeat steps 3-5 until the entire input signal has been covered.</p></li>
</ol>
<p>The resulting output signal represents how the kernel has “filtered” or modified the input signal, highlighting certain features or patterns based on the kernel’s characteristics.</p>
<p>This process can be extended to 2D (for images) or higher dimensions, where the kernel slides over the input in all dimensions.</p>
<p>For a 1d array this might look like this:</p>
<div id="cell-4" class="cell" data-execution_count="61">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> np.array([<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="op">-</span><span class="dv">1</span>, <span class="dv">10</span>, <span class="op">-</span><span class="dv">4</span>])</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> np.array([<span class="dv">1</span>,<span class="dv">0</span>,<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>inverted_g <span class="op">=</span> g[::<span class="op">-</span><span class="dv">1</span>]  <span class="co"># {-1 0 1}</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"f: </span><span class="sc">{</span>f<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"g: </span><span class="sc">{</span>g<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"inverted_g: </span><span class="sc">{</span>inverted_g<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>window_size <span class="op">=</span> g.shape[<span class="dv">0</span>]</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> []</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Steps in convolution, slide inverted g (say g`) over f in a loop: </span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, i <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">range</span>(<span class="bu">len</span>(f)<span class="op">-</span>window_size<span class="op">+</span><span class="dv">1</span>)):</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    slice_of_f <span class="op">=</span> f[i:i<span class="op">+</span>window_size]</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"step </span><span class="sc">{</span>idx<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">.1 element wise multiplication of f[</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">:</span><span class="sc">{</span>i<span class="op">+</span>window_size<span class="sc">}</span><span class="ss">] and g`: </span><span class="sc">{</span>slice_of_f<span class="sc">}</span><span class="ss"> * </span><span class="sc">{</span>inverted_g<span class="sc">}</span><span class="ss"> = </span><span class="sc">{</span>slice_of_f <span class="op">*</span> inverted_g<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"step </span><span class="sc">{</span>idx<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">.2 sum(</span><span class="sc">{</span>slice_of_f <span class="op">*</span> inverted_g<span class="sc">}</span><span class="ss">) = </span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">sum</span>(slice_of_f <span class="op">*</span> inverted_g)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    result.append(np.<span class="bu">sum</span>(slice_of_f <span class="op">*</span> inverted_g))</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"result: </span><span class="sc">{</span>[result[j] <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(result))]<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"final result of (f*g): </span><span class="sc">{</span>result<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>f: [ 1  2  3 -1 10 -4]
g: [ 1  0 -1]
inverted_g: [-1  0  1]

Steps in convolution, slide inverted g (say g`) over f in a loop: 

step 1.1 element wise multiplication of f[0:3] and g`: [1 2 3] * [-1  0  1] = [-1  0  3]
step 1.2 sum([-1  0  3]) = 2
result: [2]

step 2.1 element wise multiplication of f[1:4] and g`: [ 2  3 -1] * [-1  0  1] = [-2  0 -1]
step 2.2 sum([-2  0 -1]) = -3
result: [2, -3]

step 3.1 element wise multiplication of f[2:5] and g`: [ 3 -1 10] * [-1  0  1] = [-3  0 10]
step 3.2 sum([-3  0 10]) = 7
result: [2, -3, 7]

step 4.1 element wise multiplication of f[3:6] and g`: [-1 10 -4] * [-1  0  1] = [ 1  0 -4]
step 4.2 sum([ 1  0 -4]) = -3
result: [2, -3, 7, -3]


final result of (f*g): [2, -3, 7, -3]</code></pre>
</div>
</div>
<p>We also have a few types of convolutions, based on how much padding is added to the input signal:</p>
<ol type="1">
<li><strong>Valid Convolution</strong>:
<ul>
<li>The output is smaller than the input. No padding is applied.</li>
<li>Output length = length(f) - length(g) + 1 = 5 - 3 + 1 = 3</li>
</ul></li>
<li><strong>Same Convolution</strong>:
<ul>
<li>Padding is applied to keep the output size the same as the input.</li>
<li>We add 1 zero on each side of the input: [0, 1, 2, 3, 4, 5, 0].</li>
<li>Output length = length(f) = 5</li>
</ul></li>
<li><strong>Full Convolution</strong>:
<ul>
<li>Maximum padding is applied.</li>
<li>Output length = length(f) + length(g) - 1 = 5 + 3 - 1 = 7.</li>
<li>Here, we add 2 zeros on each side of the input: [0, 0, 1, 2, 3, 4, 5, 0, 0]<br>
(num of zeros=length(g)-1)</li>
</ul></li>
</ol>
<div id="cell-6" class="cell" data-execution_count="74">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> np.array([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>] )</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> np.array([<span class="dv">1</span>,<span class="dv">0</span>,<span class="op">-</span><span class="dv">1</span>,<span class="dv">3</span>])</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"f: </span><span class="sc">{</span>f<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"g (kernel): </span><span class="sc">{</span>g<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Valid Convolution: </span><span class="sc">{</span>np<span class="sc">.</span>convolve(f, g, mode<span class="op">=</span><span class="st">'valid'</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Same Convolution: </span><span class="sc">{</span>np<span class="sc">.</span>convolve(f, g, mode<span class="op">=</span><span class="st">'same'</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Full Convolution: </span><span class="sc">{</span>np<span class="sc">.</span>convolve(f, g, mode<span class="op">=</span><span class="st">'full'</span>)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Valid Convolution: [5 8]
Same Convolution: [2 2 5 8 5]
Full Convolution: [ 1  2  2  5  8  5  7 15]</code></pre>
</div>
</div>
<p>That wasnt so hard was it? The concept of convolution seems simple enough. Slide one signal over another and each time, do element wise multiplication and summation to get a value.</p>
<p>Lets look at an example for 2d arrays.</p>
<p>Lets take 2 matrices <span class="math inline">\(f\)</span> &amp; <span class="math inline">\(g\)</span> of shapes (5,5) and (3,3). First we need to flip the <span class="math inline">\(g\)</span> both horizontally and vertically. Then, for each <span class="math inline">\(g\)</span> sized block in <span class="math inline">\(f\)</span>, we do element-wise multiplication then summation. This gives us a resulting (3,3) matrix (valid-convolution).</p>
<p>Lets see how this works.</p>
<div id="cell-8" class="cell" data-execution_count="89">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> np.random.rand(<span class="dv">5</span>,<span class="dv">5</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> np.array([[<span class="dv">1</span>,<span class="dv">0</span>,<span class="op">-</span><span class="dv">1</span>],[<span class="dv">2</span>,<span class="dv">0</span>,<span class="op">-</span><span class="dv">2</span>],[<span class="dv">3</span>,<span class="dv">0</span>,<span class="op">-</span><span class="dv">3</span>]])</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>inverted_g <span class="op">=</span> g[::<span class="op">-</span><span class="dv">1</span>, ::<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"(f): </span><span class="ch">\n</span><span class="sc">{</span>f<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"(g): </span><span class="ch">\n</span><span class="sc">{</span>g<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"inverted g, ie (g`): </span><span class="ch">\n</span><span class="sc">{</span>inverted_g<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(f): 
[[0.23919993 0.26375948 0.29688748 0.11150198 0.18742085]
 [0.03906332 0.84585776 0.93079439 0.71811113 0.0409505 ]
 [0.70677725 0.5303402  0.6267753  0.3776878  0.85878914]
 [0.55914983 0.44782982 0.05075409 0.67132382 0.70423151]
 [0.19054968 0.44657225 0.66843129 0.01343633 0.55834927]]

(g): 
[[ 1  0 -1]
 [ 2  0 -2]
 [ 3  0 -3]]

inverted g, ie (g`): 
[[-3  0  3]
 [-2  0  2]
 [-1  0  1]]
</code></pre>
</div>
</div>
<div id="cell-9" class="cell" data-execution_count="90">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>f_rows, f_columns <span class="op">=</span> f.shape </span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>g_rows, g_columns <span class="op">=</span> g.shape</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> np.zeros((f_rows<span class="op">-</span>g_rows<span class="op">+</span><span class="dv">1</span>, f_columns<span class="op">-</span>g_columns<span class="op">+</span><span class="dv">1</span>))</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Convolution steps:"</span>)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(f_rows<span class="op">-</span>g_rows<span class="op">+</span><span class="dv">1</span>):</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(f_columns<span class="op">-</span>g_columns<span class="op">+</span><span class="dv">1</span>):</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>        item <span class="op">=</span> f[i:i<span class="op">+</span>g_rows, j:j<span class="op">+</span>g_columns] <span class="op">*</span> inverted_g</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> i<span class="op">&lt;</span><span class="dv">3</span> <span class="kw">and</span> j<span class="op">==</span><span class="dv">0</span>:</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"step </span><span class="sc">{</span>i<span class="op">+</span>j<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ch">\n</span><span class="ss">-&gt;sum(f[</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">:</span><span class="sc">{</span>i<span class="op">+</span>g_rows<span class="sc">}</span><span class="ss">, </span><span class="sc">{</span>j<span class="sc">}</span><span class="ss">:</span><span class="sc">{</span>j<span class="op">+</span>g_columns<span class="sc">}</span><span class="ss">] * g`): </span><span class="ch">\n</span><span class="sc">{</span>item<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"result[</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">,</span><span class="sc">{</span>j<span class="sc">}</span><span class="ss">] -&gt; </span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">sum</span>(item)<span class="sc">:.4f}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>        result[i,j] <span class="op">=</span> np.<span class="bu">sum</span>(item)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"... and so on.</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"final result: </span><span class="ch">\n</span><span class="sc">{</span>result<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Convolution steps:
step 1
-&gt;sum(f[0:3, 0:3] * g`): 
[[-0.7175998   0.          0.89066245]
 [-0.07812665  0.          1.86158878]
 [-0.70677725  0.          0.6267753 ]]
result[0,0] -&gt; 1.8765

step 2
-&gt;sum(f[1:4, 0:3] * g`): 
[[-0.11718997  0.          2.79238318]
 [-1.4135545   0.          1.25355059]
 [-0.55914983  0.          0.05075409]]
result[1,0] -&gt; 2.0068

step 3
-&gt;sum(f[2:5, 0:3] * g`): 
[[-2.12033176  0.          1.88032589]
 [-1.11829965  0.          0.10150818]
 [-0.19054968  0.          0.66843129]]
result[2,0] -&gt; -0.7789

... and so on.

final result: 
[[ 1.87652283 -0.86491817 -1.87607385]
 [ 2.00679355 -0.46505069 -1.55202658]
 [-0.77891572 -0.44410511  1.89291435]]
</code></pre>
</div>
</div>
</section>
</section>
<section id="neural-networks" class="level2">
<h2 class="anchored" data-anchor-id="neural-networks">Neural networks</h2>
<p>Now that we clearly understand what a convolution is, lets get back to neural networks. Suppose you wanted to classify images before CNNs were developed. How would you do it? In most cases, you would use some pre-determined filters to extract features from the images and then use a fully connected network to classify the images. Those features could be:</p>
<ol type="1">
<li><p>Edge filters: Used to detect edges in images. Common edge detection filters include:</p>
<ul>
<li>Sobel filter: Emphasizes horizontal or vertical edges</li>
<li>Prewitt filter: Similar to Sobel, but with different coefficients</li>
<li>Laplacian filter: Detects edges in all directions</li>
</ul></li>
<li><p>Texture filters: Used to capture texture information:</p>
<ul>
<li>Gabor filters: Detect specific frequencies and orientations</li>
<li>Laws’ texture energy measures: A set of filters for texture analysis</li>
</ul></li>
<li><p>Color histograms: Represent the distribution of colors in an image</p></li>
<li><p>SIFT (Scale-Invariant Feature Transform): Detects and describes local features in images</p></li>
<li><p>HOG (Histogram of Oriented Gradients): Counts occurrences of gradient orientations in localized portions of an image</p></li>
<li><p>Haar-like features: Used in face detection, these features look at rectangular regions and sum up pixel intensities</p></li>
</ol>
<p>After applying these filters, you would typically:</p>
<ol type="1">
<li>Extract the resulting features</li>
<li>Possibly apply dimensionality reduction techniques like PCA</li>
<li>Feed the processed features into a classifier such as SVM, Random Forest, or a simple neural network</li>
</ol>
<p>This approach, while effective for certain tasks, had limitations: - Handcrafted features might not capture all relevant information - The process was often computationally expensive - Feature engineering required domain expertise</p>
<p>CNNs addressed these issues by learning the filters automatically during training, leading to more effective and adaptable vision models. Let us look at all the important components of a CNN in the next section.</p>
</section>
<section id="convolutional-layer" class="level2">
<h2 class="anchored" data-anchor-id="convolutional-layer">Convolutional layer</h2>
<p>We now understand why handcrafted fatures are hard to come up with. Lets back up for a second and remember our old friends feed forward (FF) networks. What is the problem with using feed forward networks to process images? Specifically why dont we just give the FF network the raw pixels and let it learn?</p>
<p>As it turns out, there are quite a few things:</p>
<p>Suppose we have a (224,224,3) sized input-image. Thats a total of 150528 data-points. suppose i want to have a output vector of length 1000 (classifier with 1k classes), this gives me a total of roughly 150k * 1k = 150 million parameters, where we have 1k parameters for each input pixel! That is a LOTT of parameters.</p>
<p>So how can we use the inherent nature of images and image-data to construct better models? We also learned convolutions in the previous section. Maybe that gives you some hint?</p>
<p>Pixel data is inherently very locally dependent. This is very different from tabular data, for example, a housing price dataset where each feature is largely independent of each other. By design feedforward networks do not allow for this kind of information to be shared between different data points in the network. This is beacause for each linear layer, a output shaped weight matrix is learned for each point in the input. This seems very inefficient.</p>
<p>What if instead of treating each individual pixel as a different input, we treat a patch of pixels as a single input? This means we get one output for a patch of pixels. This is done via convolution. We can learn a lot of small filters that will interact with our image and get us some useful features which can then be fed to a FF network.</p>
<p>This is exactly what a convolutional layer does. It consists of a set of learnable filters that slide over the input image and compute the output. If the input image is of size <span class="math inline">\((H_{in}, W_{in}, C_{in})\)</span>, and we have <span class="math inline">\(C_{out}\)</span> filters of size <span class="math inline">\((k,k,C_{in})\)</span>, the output of the convolutional layer is of size <span class="math inline">\((H_{out}, W_{out}, C_{out})\)</span>. Each filter slides over the entire input volume and produces a 2d matrix of size <span class="math inline">\((H_{out}, W_{out})\)</span>. And this is done for all the filters in the layer. So the output of the convolutional layer is a 3d tensor of size <span class="math inline">\((H_{out}, W_{out}, C_{out})\)</span>.</p>
<p>Note that the filters will always have depth equal to the input volume’s depth.</p>
<p>The number of parameters learned here would be <span class="math inline">\((k*k*C_{in}*C_{out})\)</span>. So for a conv layer with 64 filters of size (3x3) for an input image of size (224x224x3), we would have 1792 parameters, ehich is orders of magnitutde smaller already. Much more efficient isn’t it?</p>
<!-- 
1. Feed forward networks do not share information between different data points in the network. For example if X = [0,1,2,3] is a vector of input to the network, all the interactions between weights happen independently for each data point in one sample of data.
This works fine for tabular features of some data, because they actually are not dependent on their spatial postion wrt each other. The model will learn the same if you shuffle all columns of a dataset. <br><br>But images pixels are a different type of data. They are inherently very locally dependent. If you look at a single pixel, it is very likely to be highly correlated with its neighboring pixels. Hence our network should process atleast patches of images at a time. 

2. Earlier when classical image processing methods were being used, many a times hand-made "filters" were used to extract features from images. In CNNs, we learn these filters! and we learn a lot of them. So think of each layer in this CNN as having a lot of these filters which are learned during network. We'll soon visualize what concepts they learn.

3. Another concept that helps is parameter sharing. We could in thoery have different set of filters for different patches in the image, but this would shoot up the parameter count of our model. So in a single layer, we use a single set of filters for all patches in the image. -->
<div id="cell-12" class="cell" data-execution_count="92">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_total_params(model):</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> model.parameters())</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> nn.Linear(<span class="dv">150528</span>, <span class="dv">1000</span>)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Total params in a linear layer of shape (150528, 1000): </span><span class="sc">{</span>get_total_params(model)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> nn.Conv2d(<span class="dv">3</span>, <span class="dv">64</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, stride<span class="op">=</span><span class="dv">1</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Total params in a conv layer with kernel size (3,3) and 64 filters: </span><span class="sc">{</span>get_total_params(model)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Total params in a linear layer of shape (150528, 1000): 150529000
Total params in a conv layer with kernel size (3,3) and 64 filters: 1792</code></pre>
</div>
</div>
<p>Let us visualize the shapes of the input and output of a convolutional layer. (ignoring batch dimension for simplicity)</p>
<p>Images are typically represented as 3D tensors: <span class="math inline">\((H_{in}, W_{in}, C_{in})\)</span></p>
<p>Think of this as a stack of 2D images, where: - <span class="math inline">\(H_{in}\)</span> is the height - <span class="math inline">\(W_{in}\)</span> is the width - <span class="math inline">\(C_{in}\)</span> is the number of channels (e.g., 3 for RGB)</p>
<p>Now, let’s break down the convolution operation:</p>
<ol type="1">
<li>The Filter (or Kernel)
<ul>
<li>We have <span class="math inline">\(C_{out}\)</span> filters, each of size <span class="math inline">\((k, k, C_{in})\)</span></li>
<li>Each filter slides across the entire input image</li>
</ul></li>
<li>The Sliding Window
<ul>
<li>Imagine a window of size <span class="math inline">\((k, k)\)</span> moving across the image</li>
<li>At each position, we perform a dot product between the filter and the image patch</li>
</ul></li>
<li>The Output
<ul>
<li>For each filter, we get a 2D output <span class="math inline">\((H_{out}, W_{out})\)</span></li>
<li>Stacking these for all <span class="math inline">\(C_{out}\)</span> filters gives us <span class="math inline">\((H_{out}, W_{out}, C_{out})\)</span></li>
</ul></li>
</ol>
<p>Key Parameters: - Stride (<span class="math inline">\(S\)</span>): How many pixels we move the filter each step, if stride is 1, the filter moves 1 pixel inat a time. Doubling the stride will reduce output size by half. - Padding (<span class="math inline">\(P\)</span>): Extra zeros added around the input image edges. Image can be padded with other values too. padding is done on both sides of the height and width dimensions. - Dilation (<span class="math inline">\(D\)</span>): a parameter that controls the stride of elements in the window. default=1.</p>
<p>Output Size Formula:</p>
<ul>
<li><span class="math inline">\(H_{out} = (H_{in} - k + 2P) / S + 1\)</span></li>
<li><span class="math inline">\(W_{out} = (W_{in} - k + 2P) / S + 1\)</span></li>
</ul>
<p>Intuition: - Larger stride → Smaller output (we’re skipping pixels) - More padding → Larger output (we’re adding extra space to convolve over) (as we saw in different types of convolution)</p>
<p>Summarising,</p>
<ul>
<li>input: <span class="math inline">\((H_{in}, W_{in}, C_{in})\)</span></li>
<li>conv_layer params:
<ul>
<li>filter: <span class="math inline">\((k, k, C_{in})\)</span></li>
<li>num_filters: <span class="math inline">\(C_{out}\)</span></li>
<li>stride: <span class="math inline">\(S\)</span></li>
<li>padding: <span class="math inline">\(P\)</span></li>
</ul></li>
<li>output: <span class="math inline">\((H_{out}, W_{out}, C_{out})\)</span>, where
<ul>
<li><span class="math inline">\(H_{out} = (H_{in} - k + 2P) / S + 1\)</span></li>
<li><span class="math inline">\(W_{out} = (W_{in} - k + 2P) / S + 1\)</span></li>
</ul></li>
</ul>
<p>For a visual understanding of how all these parameters interact, check out this <a href="https://ezyang.github.io/convolution-visualizer/">convolution visualizer</a>.</p>
</section>
<section id="other-layers" class="level2">
<h2 class="anchored" data-anchor-id="other-layers">Other layers</h2>
<p>Conolutional layers are usually followed by activation functions like ReLU and then a pooling layer.</p>
<section id="pooling-layer" class="level3">
<h3 class="anchored" data-anchor-id="pooling-layer">Pooling layer</h3>
<p>Pooling layer? Yes, pooling layer. Given a volume of input, instead of using filters, we can use non-parameterized operations like min and max to downsample the data and get a smaller volume. That’s what pooling does. It reduces the H and W dimensions of the input volume, keeping the depth the same. But why would we do something like that? Two main reasons:</p>
<ol type="1">
<li>Reduce the number of parameters: By reducing the number of parameters, the model can learn more general features.</li>
<li>Reduce the amount of overfitting: By reducing the amount of overfitting, the model can learn more robust features.</li>
</ol>
<p>The entire operation is the same as the convolutional layer except instead of convolving <span class="math inline">\(f\)</span> with a filter <span class="math inline">\(g\)</span> of size <span class="math inline">\((k,k, C_{in})\)</span>, we take the max/mean of <span class="math inline">\(f\)</span> for each patch of size <span class="math inline">\((k,k, C_{in})\)</span>.</p>
<p>Let’s look at an example of max pooling, which is the most common type of pooling:</p>
<div id="cell-15" class="cell" data-execution_count="81">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Input feature map</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="bu">input</span> <span class="op">=</span> np.array([</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">1</span>],</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>[<span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">4</span>, <span class="dv">2</span>],</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>[<span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">4</span>],</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">5</span>]</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Max pooling with 2x2 filter and stride 2</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> max_pool(<span class="bu">input</span>, filter_size, stride):</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    height, width <span class="op">=</span> <span class="bu">input</span>.shape</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>    output_height <span class="op">=</span> (height <span class="op">-</span> filter_size) <span class="op">//</span> stride <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>    output_width <span class="op">=</span> (width <span class="op">-</span> filter_size) <span class="op">//</span> stride <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> np.zeros((output_height, output_width))</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(output_height):</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(output_width):</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>            start_i <span class="op">=</span> i <span class="op">*</span> stride</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>            start_j <span class="op">=</span> j <span class="op">*</span> stride</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>            window <span class="op">=</span> <span class="bu">input</span>[start_i:start_i<span class="op">+</span>filter_size, start_j:start_j<span class="op">+</span>filter_size]</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>            output[i, j] <span class="op">=</span> np.<span class="bu">max</span>(window)</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> output</span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> max_pool(<span class="bu">input</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Input:"</span>)</span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">input</span>)</span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">After 2x2 Max Pooling:"</span>)</span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"""Result: </span></span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a><span class="ss">[[ max(f[0:2, 0:2]) max(f[0:2, 2:4])]</span></span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a><span class="ss"> [ max(f[2:4, 0:2]) max(f[2:4, 2:4])]]</span></span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a><span class="ss">"""</span>)</span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(result)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Input:
[[1 3 2 1]
 [5 6 4 2]
 [7 8 9 4]
 [1 2 3 5]]

After 2x2 Max Pooling:
Result: 
[[ max(f[0:2, 0:2]) max(f[0:2, 2:4])]
 [ max(f[2:4, 0:2]) max(f[2:4, 2:4])]]

[[6. 4.]
 [8. 9.]]</code></pre>
</div>
</div>
<p>As you can see, max pooling takes the maximum value in each 2x2 region, effectively reducing the spatial dimensions of the feature map while retaining the most prominent features. Generally a stride of 2 is used, which means that pooling results in half the resolution as the input (h,w).</p>
</section>
<section id="activation-layer" class="level3">
<h3 class="anchored" data-anchor-id="activation-layer">Activation layer</h3>
<p>Activations used are sigmoid, ReLu, and tanh. Since VGGs and deeper networks use ReLu, it is common to see ReLu used in CNNs. This is because ReLu partially solves the vanishing gradient problem, which is a common problem in deep networks. Read more about this <a href="https://stats.stackexchange.com/a/240491">here</a>.</p>
<p>But what the ReLU layer does is very simple, it applies max(0, x) to each element in the input. Effectively, it zeros out negative values, and leaves positive values unchanged.</p>
</section>
<section id="other-jargon" class="level3">
<h3 class="anchored" data-anchor-id="other-jargon">Other jargon</h3>
<p>Before we dive into training a model, let’s review some important jargon related to CNNs:</p>
<ul>
<li>filters: also called kernels. they are learnable parameters in a convolutional layer. Each filter is a small matrix (usually 3x3 or 5x5) that slides over the input image to detect specific features. The values in these filters are updated during training to learn important features for the task at hand.</li>
<li>activation maps: the output when a [Conv-&gt;Relu] filter interacts with entire image.</li>
<li>feature maps: the output of a convolutional layer. (before the activation)</li>
<li>depth: refers to the number of channels.</li>
<li>receptive field: the area of the input that a given filter is able to see at a time is called the receptive field.</li>
</ul>
<!-- ## CNNs from scratch!
 
Let us implement a CNN from scratch. 

Starting with the Convolutional layer.

```python
import torch 

class ConvLayer:
    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.kernel_size = kernel_size
        self.stride = stride
        self.padding = padding
        self.weights = torch.randn(out_channels, in_channels, kernel_size, kernel_size)
        self.biases = torch.zeros(out_channels)

    def forward(self, x):
        if x.ndim != 4:
            raise ValueError("Input tensor must have 4 dimensions: (batch_size, in_channels, height, width)")
        if x.shape[1] != self.in_channels:
            raise ValueError(f"Expected input shape to have {self.in_channels} channels, but got {x.shape[1]}")
'''
# broadcast weights across batch, and then perform conv operation
# conv operation
    # apply padding
    start with a patch  of k sized kernel and do element wise operation in 2 nested loops (across H and W)
    
    B*C*H*W * 
'''
``` -->
</section>
</section>
<section id="a-simple-cnn-architecture" class="level2">
<h2 class="anchored" data-anchor-id="a-simple-cnn-architecture">A Simple CNN architecture</h2>
<p>Lets assume a simple task of image classification. The most common form of a CNN architecture stacks a few CONV-RELU layers, follows them with POOL layers, and repeats this pattern until the image volume has reduced to a small size. At some point, it is common to transition to fully-connected layers. The last fully-connected layer holds the output, such as the class scores. In other words, the most common ConvNet architectures follow the pattern:</p>
<p><code>INPUT -&gt; [[CONV -&gt; RELU]*N -&gt; POOL?]*M -&gt; [FC -&gt; RELU]*K -&gt; FC</code></p>
<p>here FC: feed-forward layer.</p>
<p>Note that since architectures like <a href="https://arxiv.org/pdf/1512.03385">Resnet</a> and <a href="https://arxiv.org/pdf/1409.4842">Inception</a> emerged, this is not the case, and the CNNs feature more intricate and different connectivity structures.</p>
</section>
<section id="cnn-characteristics" class="level2">
<h2 class="anchored" data-anchor-id="cnn-characteristics">CNN characteristics</h2>
<p>While we are here, let us also take note of some characteristics of CNNs:</p>
<ul>
<li><strong>Sparse connectivity</strong>: CNNs focus on local patterns in data, particularly useful for spatial data like images. A single patch in feature map is connected to only a small patch of image (in MLPs there is dense/full connection).</li>
<li><strong>Parameter sharing</strong>: the same kernel/filter slides across the image. ie different neurons in each activation map is calculated using the same filter. In MLPs each neuron in the output space is calculated using different weight values. this makes it efficient for computation.</li>
<li><strong>Spatial hierarchy</strong>: CNNs build a hierarchy of increasingly abstract features. Lower layers detect simple features (e.g., edges), while deeper layers combine these to detect more complex patterns.</li>
<li><strong>Translation invariance</strong>: CNNs can recognize patterns regardless of their position in the input. This is because we are using filters that slide over patches of data, so information is processed in the same way for different patches of data This is crucial for tasks like object recognition in images.</li>
</ul>
<div id="fig-cnn-activation-maps" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cnn-activation-maps-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="visualizing-activation-maps-cnns.png" style="width:90.0%" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cnn-activation-maps-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: visualizing activation maps in cnns. From the paper ‘Visualizing and Understanding Convolutional Networks’
</figcaption>
</figure>
</div>
<p>Have a look at <a href="https://arxiv.org/pdf/1311.2901">this</a> wonderful paper that dives deep into visualizing and understanding Cnns.</p>
</section>
<section id="lets-train-a-model-yaar" class="level2">
<h2 class="anchored" data-anchor-id="lets-train-a-model-yaar">Lets train a model yaar</h2>
<p>I’d be remiss if I let you finish here thinking that you got CNNs down. Just for old times sake, lets train a model to classify images from the fashion mnist dataset. The dataset contains very small grayscale (ie single channel) images of size (28*28).</p>
<blockquote class="blockquote">
<p>the below code is all generated by claude-sonnet-3.5, bcuz its kinda boring to train a toy model on a toy dataset, that too for classification. dont worry though, ill soon be back with a more interesting vision problem to get our hands dirty.</p>
</blockquote>
<p>Training itself is pretty straightforward. We split the data into train-test, and then train the model for a few epochs. We use the Adam optimizer and CrossEntropyLoss as the loss function. The outputs of the model are bare logits, which the loss functions accepts with targets. A learning rate of 0.001 is used for the optimizer. In the end we test on the test set, and print the accuracy.</p>
<div id="cell-22" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.transforms <span class="im">as</span> transforms</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchsummary <span class="im">import</span> summary</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the CNN architecture</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SimpleCNN(nn.Module):</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(SimpleCNN, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv1 <span class="op">=</span> nn.Conv2d(<span class="dv">1</span>, <span class="dv">32</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)     <span class="co"># input channels in layer1 is equal to number of input channels in the input image</span></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv2 <span class="op">=</span> nn.Conv2d(<span class="dv">32</span>, <span class="dv">64</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pool <span class="op">=</span> nn.MaxPool2d(<span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv3 <span class="op">=</span> nn.Conv2d(<span class="dv">64</span>, <span class="dv">32</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc1 <span class="op">=</span> nn.Linear(<span class="dv">32</span> <span class="op">*</span> <span class="dv">3</span> <span class="op">*</span> <span class="dv">3</span>, <span class="dv">128</span>)</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc2 <span class="op">=</span> nn.Linear(<span class="dv">128</span>, <span class="dv">10</span>)</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.pool(torch.relu(<span class="va">self</span>.conv1(x)))</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.pool(torch.relu(<span class="va">self</span>.conv2(x)))</span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.pool(torch.relu(<span class="va">self</span>.conv3(x)))</span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">32</span> <span class="op">*</span> <span class="dv">3</span> <span class="op">*</span> <span class="dv">3</span>)     <span class="co"># flattening the tensor to feed it to FC layer</span></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> torch.relu(<span class="va">self</span>.fc1(x))</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.fc2(x)</span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Set device</span></span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"mps"</span> <span class="cf">if</span> torch.backends.mps.is_built() <span class="cf">else</span> <span class="st">"cpu"</span>)</span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"device: </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Load and preprocess the Fashion MNIST dataset (just plain old standardization)</span></span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([transforms.ToTensor(), transforms.Normalize((<span class="fl">0.5</span>,), (<span class="fl">0.5</span>,))])</span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> torchvision.datasets.FashionMNIST(root<span class="op">=</span><span class="st">'./data'</span>, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> torchvision.datasets.FashionMNIST(root<span class="op">=</span><span class="st">'./data'</span>, train<span class="op">=</span><span class="va">False</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> DataLoader(train_dataset, batch_size<span class="op">=</span><span class="dv">64</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a>test_loader <span class="op">=</span> DataLoader(test_dataset, batch_size<span class="op">=</span><span class="dv">64</span>, shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the model, loss function, and optimizer</span></span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SimpleCNN()</span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-47"><a href="#cb13-47" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize model summary</span></span>
<span id="cb13-48"><a href="#cb13-48" aria-hidden="true" tabindex="-1"></a>summary(model, (<span class="dv">1</span>, <span class="dv">28</span>, <span class="dv">28</span>), device<span class="op">=</span><span class="st">"cpu"</span>)</span>
<span id="cb13-49"><a href="#cb13-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-50"><a href="#cb13-50" aria-hidden="true" tabindex="-1"></a>model.to(device)</span>
<span id="cb13-51"><a href="#cb13-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-52"><a href="#cb13-52" aria-hidden="true" tabindex="-1"></a>criterion <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb13-53"><a href="#cb13-53" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">0.001</span>)</span>
<span id="cb13-54"><a href="#cb13-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-55"><a href="#cb13-55" aria-hidden="true" tabindex="-1"></a><span class="co"># Training loop</span></span>
<span id="cb13-56"><a href="#cb13-56" aria-hidden="true" tabindex="-1"></a>num_epochs <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb13-57"><a href="#cb13-57" aria-hidden="true" tabindex="-1"></a>all_losses <span class="op">=</span> []</span>
<span id="cb13-58"><a href="#cb13-58" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb13-59"><a href="#cb13-59" aria-hidden="true" tabindex="-1"></a>    model.train()</span>
<span id="cb13-60"><a href="#cb13-60" aria-hidden="true" tabindex="-1"></a>    epoch_losses <span class="op">=</span> []</span>
<span id="cb13-61"><a href="#cb13-61" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch_idx, (data, targets) <span class="kw">in</span> <span class="bu">enumerate</span>(train_loader):</span>
<span id="cb13-62"><a href="#cb13-62" aria-hidden="true" tabindex="-1"></a>        data, targets <span class="op">=</span> data.to(device), targets.to(device)</span>
<span id="cb13-63"><a href="#cb13-63" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-64"><a href="#cb13-64" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb13-65"><a href="#cb13-65" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> model(data)</span>
<span id="cb13-66"><a href="#cb13-66" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> criterion(outputs, targets)</span>
<span id="cb13-67"><a href="#cb13-67" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb13-68"><a href="#cb13-68" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb13-69"><a href="#cb13-69" aria-hidden="true" tabindex="-1"></a>        epoch_losses.append(loss.item())</span>
<span id="cb13-70"><a href="#cb13-70" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-71"><a href="#cb13-71" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Epoch [</span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>num_epochs<span class="sc">}</span><span class="ss">], Loss: </span><span class="sc">{</span>np<span class="sc">.</span>mean(epoch_losses)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb13-72"><a href="#cb13-72" aria-hidden="true" tabindex="-1"></a>    all_losses.extend(epoch_losses)</span>
<span id="cb13-73"><a href="#cb13-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-74"><a href="#cb13-74" aria-hidden="true" tabindex="-1"></a><span class="co"># plot train loss curve</span></span>
<span id="cb13-75"><a href="#cb13-75" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb13-76"><a href="#cb13-76" aria-hidden="true" tabindex="-1"></a>plt.plot(all_losses)</span>
<span id="cb13-77"><a href="#cb13-77" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Epoch'</span>)</span>
<span id="cb13-78"><a href="#cb13-78" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb13-79"><a href="#cb13-79" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Training Loss Curve'</span>)</span>
<span id="cb13-80"><a href="#cb13-80" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb13-81"><a href="#cb13-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-82"><a href="#cb13-82" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluation</span></span>
<span id="cb13-83"><a href="#cb13-83" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb13-84"><a href="#cb13-84" aria-hidden="true" tabindex="-1"></a>correct <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb13-85"><a href="#cb13-85" aria-hidden="true" tabindex="-1"></a>total <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb13-86"><a href="#cb13-86" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb13-87"><a href="#cb13-87" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> data, targets <span class="kw">in</span> test_loader:</span>
<span id="cb13-88"><a href="#cb13-88" aria-hidden="true" tabindex="-1"></a>        data, targets <span class="op">=</span> data.to(device), targets.to(device)</span>
<span id="cb13-89"><a href="#cb13-89" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> model(data)</span>
<span id="cb13-90"><a href="#cb13-90" aria-hidden="true" tabindex="-1"></a>        _, predicted <span class="op">=</span> torch.<span class="bu">max</span>(outputs.data, <span class="dv">1</span>)</span>
<span id="cb13-91"><a href="#cb13-91" aria-hidden="true" tabindex="-1"></a>        total <span class="op">+=</span> targets.size(<span class="dv">0</span>)</span>
<span id="cb13-92"><a href="#cb13-92" aria-hidden="true" tabindex="-1"></a>        correct <span class="op">+=</span> (predicted <span class="op">==</span> targets).<span class="bu">sum</span>().item()</span>
<span id="cb13-93"><a href="#cb13-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-94"><a href="#cb13-94" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Test Accuracy: </span><span class="sc">{</span><span class="dv">100</span> <span class="op">*</span> correct <span class="op">/</span> total<span class="sc">:.2f}</span><span class="ss">%'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>device: mps
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 32, 28, 28]             320
         MaxPool2d-2           [-1, 32, 14, 14]               0
            Conv2d-3           [-1, 64, 14, 14]          18,496
         MaxPool2d-4             [-1, 64, 7, 7]               0
            Conv2d-5             [-1, 32, 7, 7]          18,464
         MaxPool2d-6             [-1, 32, 3, 3]               0
            Linear-7                  [-1, 128]          36,992
            Linear-8                   [-1, 10]           1,290
================================================================
Total params: 75,562
Trainable params: 75,562
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.37
Params size (MB): 0.29
Estimated Total Size (MB): 0.67
----------------------------------------------------------------
Epoch [1/5], Loss: 0.5107
Epoch [2/5], Loss: 0.3174
Epoch [3/5], Loss: 0.2693
Epoch [4/5], Loss: 0.2401
Epoch [5/5], Loss: 0.2185</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="00_cnn_basics_files/figure-html/cell-8-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Test Accuracy: 90.38%</code></pre>
</div>
</div>
<p>Neat!! Now let’s visualize some of the predictions.</p>
<div id="cell-24" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>class_names <span class="op">=</span> [<span class="st">'T-shirt/top'</span>, <span class="st">'Trouser'</span>, <span class="st">'Pullover'</span>, <span class="st">'Dress'</span>, <span class="st">'Coat'</span>, </span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>               <span class="st">'Sandal'</span>, <span class="st">'Shirt'</span>, <span class="st">'Sneaker'</span>, <span class="st">'Bag'</span>, <span class="st">'Ankle boot'</span>]   <span class="co"># verify using train_dataset.classes</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">5</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">6</span>))</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>fig.suptitle(<span class="st">'Sample Predictions'</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, idx <span class="kw">in</span> <span class="bu">enumerate</span>(random.sample(<span class="bu">range</span>(<span class="bu">len</span>(test_dataset)), <span class="dv">10</span>)):</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>        image, label <span class="op">=</span> test_dataset[idx]</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> model(image.unsqueeze(<span class="dv">0</span>).to(device))</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>        predicted <span class="op">=</span> output.argmax(<span class="dv">1</span>).item()</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>        ax <span class="op">=</span> axes[i <span class="op">//</span> <span class="dv">5</span>, i <span class="op">%</span> <span class="dv">5</span>]</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>        ax.imshow(image.squeeze(), cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>        ax.axis(<span class="st">'off'</span>)</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>        ax.set_title(<span class="ss">f'Pred: </span><span class="sc">{</span>class_names[predicted]<span class="sc">}</span><span class="ch">\n</span><span class="ss">True: </span><span class="sc">{</span>class_names[label]<span class="sc">}</span><span class="ss">'</span>, </span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>                     color<span class="op">=</span><span class="st">'green'</span> <span class="cf">if</span> predicted <span class="op">==</span> label <span class="cf">else</span> <span class="st">'red'</span>)</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="00_cnn_basics_files/figure-html/cell-9-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Now let us visualize the confisuion matrix to exactly see how the model is doing.</p>
<div id="cell-26" class="cell" data-execution_count="30">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># see the confusion matrix</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Collect predictions and true labels</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>y_true, y_pred <span class="op">=</span> [], []</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> data, targets <span class="kw">in</span> test_loader:</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>        data, targets <span class="op">=</span> data.to(device), targets.to(device)</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> model(data)</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>        _, predicted <span class="op">=</span> torch.<span class="bu">max</span>(outputs.data, <span class="dv">1</span>)</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>        y_true.extend(targets.cpu().numpy())</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>        y_pred.extend(predicted.cpu().numpy())</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Create and plot confusion matrix</span></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(y_true, y_pred)</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>plt.imshow(cm, interpolation<span class="op">=</span><span class="st">'nearest'</span>, cmap<span class="op">=</span><span class="st">"Pastel1"</span>)</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix'</span>)</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>tick_marks <span class="op">=</span> <span class="bu">range</span>(<span class="bu">len</span>(class_names))</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>plt.xticks(tick_marks, class_names, rotation<span class="op">=</span><span class="dv">45</span>)</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>plt.yticks(tick_marks, class_names)</span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Predicted'</span>)</span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'True'</span>)</span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Add text annotations</span></span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(cm.shape[<span class="dv">0</span>]):</span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(cm.shape[<span class="dv">1</span>]):</span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a>        plt.text(j, i, <span class="bu">str</span>(cm[i, j]), ha<span class="op">=</span><span class="st">"center"</span>, va<span class="op">=</span><span class="st">"center"</span>)</span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="00_cnn_basics_files/figure-html/cell-10-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>We can see that the model is particularly confused in the “Tshirt” &amp; “Shirt” class (less than 70% accuracy) and most confident in “Trouser”, “Sneaker”, “Bag” and “Ankle boot” (greater than 95% accuracy)</p>
</section>
<section id="concluding" class="level2">
<h2 class="anchored" data-anchor-id="concluding">Concluding</h2>
<p>I hope you clearly understand the core CNN fundamental architecture. This is just the base that’ll act as a foundation for more interesting architectures as we go on. Until then, see you in the next one!</p>
<p>Byeee :)</p>
</section>
<section id="references-and-further-reading" class="level2">
<h2 class="anchored" data-anchor-id="references-and-further-reading">References and Further Reading</h2>
<ul>
<li>sebastian raschka course material <a href="https://sebastianraschka.com/blog/2021/dl-course.html#l13-introduction-to-convolutional-neural-networks">here</a></li>
<li>CS231N Cnn notes <a href="https://cs231n.github.io/convolutional-networks/#case">here</a>. Great intuition and more detail about the shapes, local connectivity, spatial arrangement, and loads of other stuff.</li>
<li>beginner friendly article on Medium (its a great blog-series for ML) <a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721">here</a></li>
<li>Visualizing and Understanding Convolutional Networks. 2014 paper <a href="https://arxiv.org/pdf/1311.2901">here</a></li>
<li>Find out some of the modifications made on this basic architecture. This is recommended further reading. <a href="https://towardsdatascience.com/10-papers-you-should-read-to-understand-image-classification-in-the-deep-learning-era-4b9d792f45a7">here</a></li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/www\.deepamminda\.com");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>